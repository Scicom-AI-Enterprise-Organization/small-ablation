{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3239ee55-6f99-4329-ac6a-96b3eb636c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AddedToken\n",
    "from streaming import MDSWriter\n",
    "from streaming.base.format.mds.encodings import Encoding, _encodings\n",
    "from streaming import LocalDataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from multiprocess import Pool\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "\n",
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield (l[i: i + n], i // n)\n",
    "\n",
    "def multiprocessing(strings, function, cores=6, returned=True):\n",
    "    df_split = chunks(strings, len(strings) // cores)\n",
    "    pool = Pool(cores)\n",
    "    pooled = pool.map(function, df_split)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    if returned:\n",
    "        return list(itertools.chain(*pooled))\n",
    "\n",
    "class UInt32(Encoding):\n",
    "    def encode(self, obj) -> bytes:\n",
    "        return obj.tobytes()\n",
    "\n",
    "    def decode(self, data: bytes):\n",
    "        return np.frombuffer(data, np.uint32)\n",
    "\n",
    "_encodings['uint32'] = UInt32\n",
    "\n",
    "columns = {\n",
    "    'input_ids': 'uint32',\n",
    "    'position_ids': 'uint32',\n",
    "    'attention_mask': 'uint32',\n",
    "    'audio': 'str',\n",
    "    'text': 'str'\n",
    "}\n",
    "hashes = 'sha1', 'xxh64'\n",
    "\n",
    "datasets = ['ayat_aktif_pasif', 'coding', 'malaysian_reasoning', 'meta_prompt', 'multiple_choice_qa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "852be377-34dc-4b81-b570-1b191c7e0eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('Qwen/Qwen3-32B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a4d6a51-e4eb-4a15-bd44-9860c623a978",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"Scicom-intl/Malaysian-Instructions\", datasets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "489547bd-9470-4331-bf6a-e86521781f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "ds = load_dataset(\"Scicom-intl/Malaysian-Instructions\", 'ayat_aktif_pasif')\n",
    "for i in range(len(ds['train'])):\n",
    "    messages = [\n",
    "        {'role': 'user', 'content': ds['train'][i]['input']},\n",
    "        {'role': 'assistant', 'content': ds['train'][i]['output']}\n",
    "    ]\n",
    "    data.append(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2969ad75-f7b2-48d2-823a-f6265d1861f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"Scicom-intl/Malaysian-Instructions\", 'coding')\n",
    "for i in range(len(ds['train'])):\n",
    "    messages = [\n",
    "        {'role': 'user', 'content': ds['train'][i]['question']},\n",
    "        {'role': 'assistant', 'content': ds['train'][i]['answer']}\n",
    "    ]\n",
    "    data.append(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62ae0785-f52f-45e9-86f7-b148401af6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"Scicom-intl/Malaysian-Instructions\", 'malaysian_reasoning')\n",
    "for i in range(len(ds['train'])):\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': ds['train'][i]['system']},\n",
    "        {'role': 'user', 'content': ds['train'][i]['input']},\n",
    "        {'role': 'assistant', 'content': ds['train'][i]['answer'], 'reasoning_content': ds['train'][i]['reasoning']}\n",
    "    ]\n",
    "    data.append(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47e7442-6d9a-421b-b0e5-acd094b5397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"Scicom-intl/Malaysian-Instructions\", 'meta_prompt')\n",
    "for i in range(len(ds['train'])):\n",
    "    messages = [\n",
    "        {'role': 'user', 'content': ds['train'][i]['input']},\n",
    "        {'role': 'assistant', 'content': ds['train'][i]['answer']}\n",
    "    ]\n",
    "    data.append(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97e6a2a-3440-4b64-8b56-d4a7ffdd9838",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"Scicom-intl/Malaysian-Instructions\", 'multiple_choice_qa')\n",
    "for i in range(len(ds['train'])):\n",
    "    messages = [\n",
    "        {'role': 'user', 'content': ds['train'][i]['question']},\n",
    "        {'role': 'assistant', 'content': ds['train'][i]['answer']}\n",
    "    ]\n",
    "    data.append(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb928a70-ff07-4fbd-833e-f4fbd2ab1834",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57dae84-818a-455e-ba16-9135dea63d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf tokenized-qwen3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24122187-51dc-40c5-827e-8e90209dc9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collator(batch, batch_position_ids):\n",
    "    input_ids = []\n",
    "    position_ids = []\n",
    "    masks = []\n",
    "    for i in range(len(batch)):\n",
    "        l = len(batch[i])\n",
    "        input_ids.extend(batch[i])\n",
    "        position_ids.extend(batch_position_ids[i])\n",
    "        masks.append(l)\n",
    "    \n",
    "    return {\n",
    "        'input_ids': np.array(input_ids).astype(np.uint32),\n",
    "        'position_ids': np.array(position_ids).astype(np.uint32),\n",
    "        'attention_mask': np.array(masks).astype(np.uint32),\n",
    "        'audio': '',\n",
    "        'text': '',\n",
    "    }\n",
    "\n",
    "sequence_length = 1024 * 16\n",
    "def loop(files, block_size = sequence_length):\n",
    "    rows, index = files\n",
    "    out_root = f'tokenized-qwen3/tokenized-{index}'\n",
    "    os.system(f'rm -rf {out_root}')\n",
    "    count = 0\n",
    "    temp = []\n",
    "    position_ids = []\n",
    "    last_block, last_position_block = None, None\n",
    "    with MDSWriter(out=out_root, columns=columns, compression=None, hashes=hashes) as out:\n",
    "        for row in tqdm(rows):\n",
    "\n",
    "            t = tokenizer.apply_chat_template(row, tokenize=False)\n",
    "            outputs = tokenizer(t, add_special_tokens=False)\n",
    "            position = range(len(outputs['input_ids']))\n",
    "            length = len(outputs['input_ids'])\n",
    "\n",
    "            if length > block_size:\n",
    "                continue\n",
    "            \n",
    "            if count + length > block_size:\n",
    "                o = collator(temp, position_ids)\n",
    "                if o['input_ids'].shape[0] > 0:\n",
    "                    out.write(o)\n",
    "                temp = [outputs['input_ids']]\n",
    "                position_ids = [position]\n",
    "                count = length\n",
    "                \n",
    "            else:\n",
    "                temp.append(outputs['input_ids'])\n",
    "                position_ids.append(range(len(outputs['input_ids'])))\n",
    "                count += len(outputs['input_ids'])\n",
    "        \n",
    "        if len(temp):\n",
    "            o = collator(temp, position_ids)\n",
    "            if o['input_ids'].shape[0] > 0:\n",
    "                out.write(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1357d1e9-ac80-4ab2-b3a2-60090105a6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "loop((data[:100], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ad2a01-bb7b-4d2c-9a60-f1723d67de2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiprocessing(data, loop, cores = 20, returned=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab680ec2-6e38-40a0-b459-4b89e42b6168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "folders = sorted(glob('tokenized-qwen3/tokenized-*'), key = lambda x: int(x.split('-')[-1]))\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79969f63-2f46-41da-ba46-cbe05c006899",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf multipacking-qwen3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26954959-ca3c-4509-be13-9a682d1fbc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "with MDSWriter(out='multipacking-qwen3', columns=columns, compression=None, hashes=hashes) as out:\n",
    "    for f in folders:\n",
    "        try:\n",
    "            dataset = LocalDataset(local=f)\n",
    "            for i in tqdm(range(len(dataset))):\n",
    "                out.write(dataset[i])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f0b272-f278-4a35-b758-2de32e064c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = LocalDataset('multipacking-qwen3')\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe4f7b0-2d94-4283-bf8d-c5178f7427e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "malaysian-reasoning",
   "language": "python",
   "name": "malaysian-reasoning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
