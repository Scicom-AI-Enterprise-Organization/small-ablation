{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3239ee55-6f99-4329-ac6a-96b3eb636c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AddedToken\n",
    "from streaming import MDSWriter\n",
    "from streaming.base.format.mds.encodings import Encoding, _encodings\n",
    "from streaming import LocalDataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from multiprocess import Pool\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "\n",
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield (l[i: i + n], i // n)\n",
    "\n",
    "def multiprocessing(strings, function, cores=6, returned=True):\n",
    "    df_split = chunks(strings, len(strings) // cores)\n",
    "    pool = Pool(cores)\n",
    "    pooled = pool.map(function, df_split)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    if returned:\n",
    "        return list(itertools.chain(*pooled))\n",
    "\n",
    "class UInt32(Encoding):\n",
    "    def encode(self, obj) -> bytes:\n",
    "        return obj.tobytes()\n",
    "\n",
    "    def decode(self, data: bytes):\n",
    "        return np.frombuffer(data, np.uint32)\n",
    "\n",
    "_encodings['uint32'] = UInt32\n",
    "\n",
    "columns = {\n",
    "    'input_ids': 'uint32',\n",
    "    'position_ids': 'uint32',\n",
    "    'attention_mask': 'uint32',\n",
    "    'audio': 'str',\n",
    "    'text': 'str'\n",
    "}\n",
    "hashes = 'sha1', 'xxh64'\n",
    "\n",
    "datasets = ['ayat_aktif_pasif', 'coding', 'malaysian_reasoning', 'meta_prompt', 'multiple_choice_qa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "852be377-34dc-4b81-b570-1b191c7e0eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('Qwen/Qwen2.5-72B-Instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a4d6a51-e4eb-4a15-bd44-9860c623a978",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"Scicom-intl/Malaysian-Instructions\", datasets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "489547bd-9470-4331-bf6a-e86521781f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "ds = load_dataset(\"Scicom-intl/Malaysian-Instructions\", 'ayat_aktif_pasif')\n",
    "for i in range(len(ds['train'])):\n",
    "    messages = [\n",
    "        {'role': 'user', 'content': ds['train'][i]['input']},\n",
    "        {'role': 'assistant', 'content': ds['train'][i]['output']}\n",
    "    ]\n",
    "    data.append(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2969ad75-f7b2-48d2-823a-f6265d1861f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"Scicom-intl/Malaysian-Instructions\", 'coding')\n",
    "for i in range(len(ds['train'])):\n",
    "    messages = [\n",
    "        {'role': 'user', 'content': ds['train'][i]['question']},\n",
    "        {'role': 'assistant', 'content': ds['train'][i]['answer']}\n",
    "    ]\n",
    "    data.append(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62ae0785-f52f-45e9-86f7-b148401af6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"Scicom-intl/Malaysian-Instructions\", 'malaysian_reasoning')\n",
    "for i in range(len(ds['train'])):\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': ds['train'][i]['system']},\n",
    "        {'role': 'user', 'content': ds['train'][i]['input']},\n",
    "        {'role': 'assistant', 'content': ds['train'][i]['reasoning']}\n",
    "    ]\n",
    "    data.append(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f47e7442-6d9a-421b-b0e5-acd094b5397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"Scicom-intl/Malaysian-Instructions\", 'meta_prompt')\n",
    "for i in range(len(ds['train'])):\n",
    "    messages = [\n",
    "        {'role': 'user', 'content': ds['train'][i]['input']},\n",
    "        {'role': 'assistant', 'content': ds['train'][i]['answer']}\n",
    "    ]\n",
    "    data.append(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c97e6a2a-3440-4b64-8b56-d4a7ffdd9838",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"Scicom-intl/Malaysian-Instructions\", 'multiple_choice_qa')\n",
    "for i in range(len(ds['train'])):\n",
    "    messages = [\n",
    "        {'role': 'user', 'content': ds['train'][i]['question']},\n",
    "        {'role': 'assistant', 'content': ds['train'][i]['answer']}\n",
    "    ]\n",
    "    data.append(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb928a70-ff07-4fbd-833e-f4fbd2ab1834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225265"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e57dae84-818a-455e-ba16-9135dea63d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -rf tokenized-qwen2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24122187-51dc-40c5-827e-8e90209dc9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collator(batch, batch_position_ids):\n",
    "    input_ids = []\n",
    "    position_ids = []\n",
    "    masks = []\n",
    "    for i in range(len(batch)):\n",
    "        l = len(batch[i])\n",
    "        input_ids.extend(batch[i])\n",
    "        position_ids.extend(batch_position_ids[i])\n",
    "        masks.append(l)\n",
    "    \n",
    "    return {\n",
    "        'input_ids': np.array(input_ids).astype(np.uint32),\n",
    "        'position_ids': np.array(position_ids).astype(np.uint32),\n",
    "        'attention_mask': np.array(masks).astype(np.uint32),\n",
    "        'audio': '',\n",
    "        'text': '',\n",
    "    }\n",
    "\n",
    "sequence_length = 1024 * 16\n",
    "def loop(files, block_size = sequence_length):\n",
    "    rows, index = files\n",
    "    out_root = f'tokenized-qwen2/tokenized-{index}'\n",
    "    os.system(f'rm -rf {out_root}')\n",
    "    count = 0\n",
    "    temp = []\n",
    "    position_ids = []\n",
    "    last_block, last_position_block = None, None\n",
    "    with MDSWriter(out=out_root, columns=columns, compression=None, hashes=hashes) as out:\n",
    "        for row in tqdm(rows):\n",
    "\n",
    "            t = tokenizer.apply_chat_template(row, tokenize=False)\n",
    "            outputs = tokenizer(t, add_special_tokens=False)\n",
    "            position = range(len(outputs['input_ids']))\n",
    "            length = len(outputs['input_ids'])\n",
    "\n",
    "            if length > block_size:\n",
    "                continue\n",
    "            \n",
    "            if count + length > block_size:\n",
    "                o = collator(temp, position_ids)\n",
    "                if o['input_ids'].shape[0] > 0:\n",
    "                    out.write(o)\n",
    "                temp = [outputs['input_ids']]\n",
    "                position_ids = [position]\n",
    "                count = length\n",
    "                \n",
    "            else:\n",
    "                temp.append(outputs['input_ids'])\n",
    "                position_ids.append(range(len(outputs['input_ids'])))\n",
    "                count += len(outputs['input_ids'])\n",
    "        \n",
    "        if len(temp):\n",
    "            o = collator(temp, position_ids)\n",
    "            if o['input_ids'].shape[0] > 0:\n",
    "                out.write(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1357d1e9-ac80-4ab2-b3a2-60090105a6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 3184.16it/s]\n"
     ]
    }
   ],
   "source": [
    "loop((data[:100], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3ad2a01-bb7b-4d2c-9a60-f1723d67de2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "  9%|█████████████████▍                                                                                                                                                                                     | 985/11263 [00:00<00:07, 1305.56it/s]TOKENIZERS_PARALLELISM=(true | false)\n",
      "  8%|███████████████                                                                                                                                                                                        | 855/11263 [00:00<00:07, 1315.93it/s]TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:02<00:00, 4901.52it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 3075.45it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:02<00:00, 4972.61it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:02<00:00, 4615.75it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:02<00:00, 4200.78it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:02<00:00, 4964.69it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:03<00:00, 3627.05it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:02<00:00, 4942.00it/s]\n",
      " 71%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                         | 8006/11263 [00:06<00:02, 1269.59it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (256540 > 131072). Running this sequence through the model will result in indexing errors\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:02<00:00, 4975.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:02<00:00, 4957.40it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:02<00:00, 5019.12it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:08<00:00, 1253.67it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:08<00:00, 1280.46it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:08<00:00, 1268.34it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:08<00:00, 1267.99it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:09<00:00, 1241.92it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:08<00:00, 1259.43it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:34<00:00, 330.24it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:31<00:00, 361.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:36<00:00, 304.91it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:54<00:00, 207.70it/s]\n"
     ]
    }
   ],
   "source": [
    "multiprocessing(data, loop, cores = 20, returned=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab680ec2-6e38-40a0-b459-4b89e42b6168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tokenized-qwen2/tokenized-0',\n",
       " 'tokenized-qwen2/tokenized-1',\n",
       " 'tokenized-qwen2/tokenized-2',\n",
       " 'tokenized-qwen2/tokenized-3',\n",
       " 'tokenized-qwen2/tokenized-4',\n",
       " 'tokenized-qwen2/tokenized-5',\n",
       " 'tokenized-qwen2/tokenized-6',\n",
       " 'tokenized-qwen2/tokenized-7',\n",
       " 'tokenized-qwen2/tokenized-8',\n",
       " 'tokenized-qwen2/tokenized-9',\n",
       " 'tokenized-qwen2/tokenized-10',\n",
       " 'tokenized-qwen2/tokenized-11',\n",
       " 'tokenized-qwen2/tokenized-12',\n",
       " 'tokenized-qwen2/tokenized-13',\n",
       " 'tokenized-qwen2/tokenized-14',\n",
       " 'tokenized-qwen2/tokenized-15',\n",
       " 'tokenized-qwen2/tokenized-16',\n",
       " 'tokenized-qwen2/tokenized-17',\n",
       " 'tokenized-qwen2/tokenized-18',\n",
       " 'tokenized-qwen2/tokenized-19',\n",
       " 'tokenized-qwen2/tokenized-20']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "folders = sorted(glob('tokenized-qwen2/tokenized-*'), key = lambda x: int(x.split('-')[-1]))\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79969f63-2f46-41da-ba46-cbe05c006899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -rf multipacking-qwen2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "26954959-ca3c-4509-be13-9a682d1fbc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1578/1578 [00:00<00:00, 3624.92it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 420/420 [00:00<00:00, 2323.01it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 418/418 [00:00<00:00, 2489.92it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 416/416 [00:00<00:00, 14958.21it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 418/418 [00:00<00:00, 2466.59it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 422/422 [00:00<00:00, 2329.19it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 425/425 [00:00<00:00, 2351.22it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2418/2418 [00:00<00:00, 3841.74it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1862/1862 [00:00<00:00, 2551.75it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1141/1141 [00:00<00:00, 5246.01it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 70/70 [00:00<00:00, 431.33it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 102/102 [00:00<00:00, 12192.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 84/84 [00:00<00:00, 10499.82it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 80/80 [00:00<00:00, 10950.47it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:00<00:00, 9869.30it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 66/66 [00:00<00:00, 9632.01it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 66/66 [00:00<00:00, 9944.46it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 66/66 [00:00<00:00, 440.47it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [00:00<00:00, 12082.13it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 66/66 [00:00<00:00, 13300.54it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 9098.27it/s]\n"
     ]
    }
   ],
   "source": [
    "with MDSWriter(out='multipacking-qwen2', columns=columns, compression=None, hashes=hashes) as out:\n",
    "    for f in folders:\n",
    "        try:\n",
    "            dataset = LocalDataset(local=f)\n",
    "            for i in tqdm(range(len(dataset))):\n",
    "                out.write(dataset[i])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e7f0b272-f278-4a35-b758-2de32e064c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10253"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = LocalDataset('multipacking-qwen2')\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fe4f7b0-2d94-4283-bf8d-c5178f7427e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': array([ 93,  93,  75,  75,  81,  82,  89,  89,  80,  80, 103, 103,  79,\n",
       "         79, 101, 102,  79,  79,  80,  81,  99,  99,  84,  84,  83,  84,\n",
       "         88,  89,  89,  90,  91,  91,  87,  88,  71,  72,  68,  67,  73,\n",
       "         73,  99,  99, 101, 101,  93,  94,  92,  92,  79,  79,  80,  80,\n",
       "         86,  85,  83,  83,  79,  79,  93,  93, 102, 102,  84,  84,  83,\n",
       "         82,  87,  88,  81,  81,  93,  93,  91,  91,  85,  86,  86,  86,\n",
       "         82,  82,  91,  91,  83,  84,  88,  87,  85,  85,  90,  90,  87,\n",
       "         87,  84,  83,  99,  99,  81,  81,  76,  76,  99,  98,  97,  97,\n",
       "         89,  89,  99,  99,  87,  88,  93,  93,  81,  82,  86,  85,  84,\n",
       "         84,  80,  80,  81,  82,  81,  81,  73,  74,  86,  85,  85,  85,\n",
       "         85,  85,  82,  81,  94,  93,  95,  95,  85,  85,  78,  78,  76,\n",
       "         75,  74,  73,  96,  95,  91,  91,  86,  87,  78,  78,  85,  85,\n",
       "         82,  81,  81,  81,  86,  87,  84,  84,  89,  89,  85,  85,  89,\n",
       "         90,  84,  85,  88,  88,  84,  84,  97,  97,  82,  81,  86,  87,\n",
       "         97,  97,  90,  89,  88,  88,  89], dtype=uint32),\n",
       " 'audio': '',\n",
       " 'input_ids': array([151644,   8948,    198, ...,     13, 151645,    198], dtype=uint32),\n",
       " 'position_ids': array([ 0,  1,  2, ..., 86, 87, 88], dtype=uint32),\n",
       " 'text': ''}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "malaysian-reasoning",
   "language": "python",
   "name": "malaysian-reasoning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
