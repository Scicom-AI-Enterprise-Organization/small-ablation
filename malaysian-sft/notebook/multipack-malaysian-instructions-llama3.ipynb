{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3239ee55-6f99-4329-ac6a-96b3eb636c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AddedToken\n",
    "from streaming import MDSWriter\n",
    "from streaming.base.format.mds.encodings import Encoding, _encodings\n",
    "from streaming import LocalDataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from multiprocess import Pool\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "\n",
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield (l[i: i + n], i // n)\n",
    "\n",
    "def multiprocessing(strings, function, cores=6, returned=True):\n",
    "    df_split = chunks(strings, len(strings) // cores)\n",
    "    pool = Pool(cores)\n",
    "    pooled = pool.map(function, df_split)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    if returned:\n",
    "        return list(itertools.chain(*pooled))\n",
    "\n",
    "class UInt32(Encoding):\n",
    "    def encode(self, obj) -> bytes:\n",
    "        return obj.tobytes()\n",
    "\n",
    "    def decode(self, data: bytes):\n",
    "        return np.frombuffer(data, np.uint32)\n",
    "\n",
    "_encodings['uint32'] = UInt32\n",
    "\n",
    "columns = {\n",
    "    'input_ids': 'uint32',\n",
    "    'position_ids': 'uint32',\n",
    "    'attention_mask': 'uint32',\n",
    "    'audio': 'str',\n",
    "    'text': 'str'\n",
    "}\n",
    "hashes = 'sha1', 'xxh64'\n",
    "\n",
    "datasets = ['ayat_aktif_pasif', 'coding', 'malaysian_reasoning', 'meta_prompt', 'multiple_choice_qa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "852be377-34dc-4b81-b570-1b191c7e0eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('unsloth/Meta-Llama-3.1-70B-Instruct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a4d6a51-e4eb-4a15-bd44-9860c623a978",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"Scicom-intl/Malaysian-Instructions\", datasets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "489547bd-9470-4331-bf6a-e86521781f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "ds = load_dataset(\"Scicom-intl/Malaysian-Instructions\", 'ayat_aktif_pasif')\n",
    "for i in range(len(ds['train'])):\n",
    "    messages = [\n",
    "        {'role': 'user', 'content': ds['train'][i]['input']},\n",
    "        {'role': 'assistant', 'content': ds['train'][i]['output']}\n",
    "    ]\n",
    "    data.append(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2969ad75-f7b2-48d2-823a-f6265d1861f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"Scicom-intl/Malaysian-Instructions\", 'coding')\n",
    "for i in range(len(ds['train'])):\n",
    "    messages = [\n",
    "        {'role': 'user', 'content': ds['train'][i]['question']},\n",
    "        {'role': 'assistant', 'content': ds['train'][i]['answer']}\n",
    "    ]\n",
    "    data.append(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62ae0785-f52f-45e9-86f7-b148401af6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"Scicom-intl/Malaysian-Instructions\", 'malaysian_reasoning')\n",
    "for i in range(len(ds['train'])):\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': ds['train'][i]['system']},\n",
    "        {'role': 'user', 'content': ds['train'][i]['input']},\n",
    "        {'role': 'assistant', 'content': ds['train'][i]['reasoning']}\n",
    "    ]\n",
    "    data.append(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f47e7442-6d9a-421b-b0e5-acd094b5397a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"Scicom-intl/Malaysian-Instructions\", 'meta_prompt')\n",
    "for i in range(len(ds['train'])):\n",
    "    messages = [\n",
    "        {'role': 'user', 'content': ds['train'][i]['input']},\n",
    "        {'role': 'assistant', 'content': ds['train'][i]['answer']}\n",
    "    ]\n",
    "    data.append(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c97e6a2a-3440-4b64-8b56-d4a7ffdd9838",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"Scicom-intl/Malaysian-Instructions\", 'multiple_choice_qa')\n",
    "for i in range(len(ds['train'])):\n",
    "    messages = [\n",
    "        {'role': 'user', 'content': ds['train'][i]['question']},\n",
    "        {'role': 'assistant', 'content': ds['train'][i]['answer']}\n",
    "    ]\n",
    "    data.append(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb928a70-ff07-4fbd-833e-f4fbd2ab1834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225265"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e57dae84-818a-455e-ba16-9135dea63d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf tokenized-llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24122187-51dc-40c5-827e-8e90209dc9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collator(batch, batch_position_ids):\n",
    "    input_ids = []\n",
    "    position_ids = []\n",
    "    masks = []\n",
    "    for i in range(len(batch)):\n",
    "        l = len(batch[i])\n",
    "        input_ids.extend(batch[i])\n",
    "        position_ids.extend(batch_position_ids[i])\n",
    "        masks.append(l)\n",
    "    \n",
    "    return {\n",
    "        'input_ids': np.array(input_ids).astype(np.uint32),\n",
    "        'position_ids': np.array(position_ids).astype(np.uint32),\n",
    "        'attention_mask': np.array(masks).astype(np.uint32),\n",
    "        'audio': '',\n",
    "        'text': '',\n",
    "    }\n",
    "\n",
    "sequence_length = 1024 * 16\n",
    "def loop(files, block_size = sequence_length):\n",
    "    rows, index = files\n",
    "    out_root = f'tokenized-llama3/tokenized-{index}'\n",
    "    os.system(f'rm -rf {out_root}')\n",
    "    count = 0\n",
    "    temp = []\n",
    "    position_ids = []\n",
    "    last_block, last_position_block = None, None\n",
    "    with MDSWriter(out=out_root, columns=columns, compression=None, hashes=hashes) as out:\n",
    "        for row in tqdm(rows):\n",
    "\n",
    "            t = tokenizer.apply_chat_template(row, tokenize=False)\n",
    "            outputs = tokenizer(t, add_special_tokens=False)\n",
    "            position = range(len(outputs['input_ids']))\n",
    "            length = len(outputs['input_ids'])\n",
    "\n",
    "            if length > block_size:\n",
    "                continue\n",
    "            \n",
    "            if count + length > block_size:\n",
    "                o = collator(temp, position_ids)\n",
    "                if o['input_ids'].shape[0] > 0:\n",
    "                    out.write(o)\n",
    "                temp = [outputs['input_ids']]\n",
    "                position_ids = [position]\n",
    "                count = length\n",
    "                \n",
    "            else:\n",
    "                temp.append(outputs['input_ids'])\n",
    "                position_ids.append(range(len(outputs['input_ids'])))\n",
    "                count += len(outputs['input_ids'])\n",
    "        \n",
    "        if len(temp):\n",
    "            o = collator(temp, position_ids)\n",
    "            if o['input_ids'].shape[0] > 0:\n",
    "                out.write(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1357d1e9-ac80-4ab2-b3a2-60090105a6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 100/100 [00:00<00:00, 2836.94it/s]\n"
     ]
    }
   ],
   "source": [
    "loop((data[:100], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3ad2a01-bb7b-4d2c-9a60-f1723d67de2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "  6%|███████████▌                                                                                                                                                                                           | 657/11263 [00:00<00:08, 1322.02it/s]TOKENIZERS_PARALLELISM=(true | false)\n",
      "  1%|██▌                                                                                                                                                                                                     | 147/11263 [00:00<00:57, 192.04it/s]TOKENIZERS_PARALLELISM=(true | false)\n",
      " 32%|██████████████████████████████████████████████████████████████▉                                                                                                                                       | 3583/11263 [00:02<00:06, 1203.78it/s]TOKENIZERS_PARALLELISM=(true | false)\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:02<00:00, 4988.22it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 5/5 [00:00<00:00, 3314.61it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:02<00:00, 4679.39it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:02<00:00, 4372.61it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:02<00:00, 5033.04it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:02<00:00, 3844.92it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:02<00:00, 5050.72it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:02<00:00, 5019.05it/s]\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (235608 > 131072). Running this sequence through the model will result in indexing errors\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:02<00:00, 5073.27it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:02<00:00, 5084.21it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:02<00:00, 5175.90it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:08<00:00, 1385.36it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:08<00:00, 1303.39it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:08<00:00, 1314.21it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:08<00:00, 1309.86it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:08<00:00, 1300.32it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:08<00:00, 1262.74it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:26<00:00, 422.42it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:30<00:00, 369.97it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:34<00:00, 328.02it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11263/11263 [00:45<00:00, 250.11it/s]\n"
     ]
    }
   ],
   "source": [
    "multiprocessing(data, loop, cores = 20, returned=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ab680ec2-6e38-40a0-b459-4b89e42b6168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tokenized-llama3/tokenized-0',\n",
       " 'tokenized-llama3/tokenized-1',\n",
       " 'tokenized-llama3/tokenized-2',\n",
       " 'tokenized-llama3/tokenized-3',\n",
       " 'tokenized-llama3/tokenized-4',\n",
       " 'tokenized-llama3/tokenized-5',\n",
       " 'tokenized-llama3/tokenized-6',\n",
       " 'tokenized-llama3/tokenized-7',\n",
       " 'tokenized-llama3/tokenized-8',\n",
       " 'tokenized-llama3/tokenized-9',\n",
       " 'tokenized-llama3/tokenized-10',\n",
       " 'tokenized-llama3/tokenized-11',\n",
       " 'tokenized-llama3/tokenized-12',\n",
       " 'tokenized-llama3/tokenized-13',\n",
       " 'tokenized-llama3/tokenized-14',\n",
       " 'tokenized-llama3/tokenized-15',\n",
       " 'tokenized-llama3/tokenized-16',\n",
       " 'tokenized-llama3/tokenized-17',\n",
       " 'tokenized-llama3/tokenized-18',\n",
       " 'tokenized-llama3/tokenized-19',\n",
       " 'tokenized-llama3/tokenized-20']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from glob import glob\n",
    "\n",
    "folders = sorted(glob('tokenized-llama3/tokenized-*'), key = lambda x: int(x.split('-')[-1]))\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79969f63-2f46-41da-ba46-cbe05c006899",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!rm -rf multipacking-llama3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26954959-ca3c-4509-be13-9a682d1fbc87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1564/1564 [00:00<00:00, 4123.98it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 430/430 [00:00<00:00, 2623.45it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 430/430 [00:00<00:00, 2563.98it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 426/426 [00:00<00:00, 16387.46it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 428/428 [00:00<00:00, 2527.00it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 432/432 [00:00<00:00, 2623.23it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 435/435 [00:00<00:00, 2542.35it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2416/2416 [00:00<00:00, 3456.22it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1860/1860 [00:00<00:00, 3347.22it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1132/1132 [00:00<00:00, 3311.15it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 73/73 [00:00<00:00, 17482.25it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 104/104 [00:00<00:00, 17918.49it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 87/87 [00:00<00:00, 17628.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 82/82 [00:00<00:00, 17899.19it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 70/70 [00:00<00:00, 17734.90it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 17873.45it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 466.34it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 17519.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 70/70 [00:00<00:00, 17657.04it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 69/69 [00:00<00:00, 17836.00it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 11715.93it/s]\n"
     ]
    }
   ],
   "source": [
    "with MDSWriter(out='multipacking-llama3', columns=columns, compression=None, hashes=hashes) as out:\n",
    "    for f in folders:\n",
    "        try:\n",
    "            dataset = LocalDataset(local=f)\n",
    "            for i in tqdm(range(len(dataset))):\n",
    "                out.write(dataset[i])\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7f0b272-f278-4a35-b758-2de32e064c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10316"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = LocalDataset('multipacking-llama3')\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fe4f7b0-2d94-4283-bf8d-c5178f7427e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attention_mask': array([ 96,  96,  78,  78,  84,  85,  92,  92,  83,  83, 106, 106,  82,\n",
       "         82, 104, 105,  81,  81,  82,  83, 100, 100,  87,  87,  86,  87,\n",
       "         91,  92,  91,  92,  94,  94,  90,  91,  73,  74,  71,  70,  75,\n",
       "         75, 100, 100, 102, 102,  96,  97,  95,  95,  82,  82,  83,  83,\n",
       "         89,  88,  86,  86,  82,  82,  96,  96, 101, 101,  85,  85,  86,\n",
       "         85,  90,  91,  82,  82,  92,  92,  94,  94,  87,  88,  89,  89,\n",
       "         85,  85,  94,  94,  86,  87,  91,  90,  86,  86,  93,  93,  90,\n",
       "         90,  87,  86, 100, 100,  84,  84,  79,  79, 102, 101, 100, 100,\n",
       "         90,  90, 102, 102,  90,  91,  96,  96,  84,  85,  86,  85,  85,\n",
       "         85,  83,  83,  84,  85,  84,  84,  75,  76,  86,  85,  88,  88,\n",
       "         88,  88,  83,  82,  97,  96,  96,  96,  88,  88,  81,  81,  76,\n",
       "         75,  75,  74,  99,  98,  94,  94,  89,  90,  81,  81,  88,  88,\n",
       "         83,  82,  84,  84,  89,  90,  85,  85,  92,  92,  86,  86,  91,\n",
       "         92,  87,  88,  89,  89,  85,  85, 100, 100,  83,  82,  89,  90,\n",
       "        100, 100], dtype=uint32),\n",
       " 'audio': '',\n",
       " 'input_ids': array([128000, 128006,   9125, ...,    276,     13, 128009], dtype=uint32),\n",
       " 'position_ids': array([ 0,  1,  2, ..., 97, 98, 99], dtype=uint32),\n",
       " 'text': ''}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "malaysian-reasoning",
   "language": "python",
   "name": "malaysian-reasoning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
