{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64ac98c2-a7b7-4b14-bdcd-30038678ebfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "class ChunkedDPO(torch.autograd.Function):\n",
    "    \n",
    "    @staticmethod\n",
    "    @torch.no_grad()\n",
    "    def forward(\n",
    "        ctx,\n",
    "        inputs_chosen, \n",
    "        inputs_rejected, \n",
    "        refs_chosen, \n",
    "        refs_rejected, \n",
    "        targets_chosen, \n",
    "        targets_rejected, \n",
    "        inputs_weight, \n",
    "        refs_weight,\n",
    "        compiled=True, \n",
    "        chunk_size=128, \n",
    "        ignore_index=-100,\n",
    "    ):\n",
    "\n",
    "        @torch.no_grad()\n",
    "        def compute_loss(input_chunk, weight, target_chunk, ignore_index=100):\n",
    "            logits = input_chunk @ weight.T\n",
    "            loss_mask = target_chunk != ignore_index\n",
    "            label_chunk = torch.where(loss_mask, target_chunk, 0)\n",
    "        \n",
    "            logits_y = logits.gather(1, label_chunk.unsqueeze(1)).squeeze(1)\n",
    "            lse = torch.logsumexp(logits, dim=1)\n",
    "            per_token_logps = (logits_y - lse) * loss_mask\n",
    "            return per_token_logps.sum()\n",
    "        \n",
    "        @torch.no_grad()\n",
    "        def get_sum_logprob(inputs, targets, weight, chunk_size=512, ignore_index=-100):\n",
    "            grad_inputs = []\n",
    "            grad_weight = torch.zeros_like(weight)\n",
    "            sum_log_prob = torch.zeros((), device=inputs.device)\n",
    "            BT, H = inputs.shape\n",
    "        \n",
    "            for start_idx in range(0, BT, chunk_size):\n",
    "                end_idx = min(start_idx + chunk_size, BT)\n",
    "                _inputs_chunk = inputs[start_idx:end_idx]          \n",
    "                _targets_chunk = targets[start_idx:end_idx] \n",
    "        \n",
    "                (chunk_grad_input, chunk_grad_weight), per_token_logps_sum = torch.func.grad_and_value(\n",
    "                    compute_loss, argnums=(0,1))(_inputs_chunk, weight, _targets_chunk)\n",
    "                grad_weight.add_(chunk_grad_weight)\n",
    "                sum_log_prob.add_(per_token_logps_sum)\n",
    "                grad_inputs.append(chunk_grad_input)\n",
    "\n",
    "            grad_inputs = torch.cat(grad_inputs, dim=0)\n",
    "            return grad_inputs, grad_weight, sum_log_prob\n",
    "        \n",
    "        @torch.no_grad()\n",
    "        def get_sum_logprob_ref(inputs, targets, weight, chunk_size=512, ignore_index=-100):\n",
    "            sum_log_prob = torch.zeros((), device=inputs.device)\n",
    "            BT, H = inputs.shape\n",
    "        \n",
    "            for start_idx in range(0, BT, chunk_size):\n",
    "                end_idx = min(start_idx + chunk_size, BT)\n",
    "                _inputs_chunk = inputs[start_idx:end_idx]          \n",
    "                _targets_chunk = targets[start_idx:end_idx] \n",
    "        \n",
    "                per_token_logps_sum = compute_loss(_inputs_chunk, weight, _targets_chunk,)\n",
    "                sum_log_prob.add_(per_token_logps_sum)\n",
    "        \n",
    "            return sum_log_prob\n",
    "    \n",
    "        torch._dynamo.maybe_mark_dynamic(inputs_chosen, 0)\n",
    "        torch._dynamo.maybe_mark_dynamic(inputs_rejected, 0)\n",
    "        torch._dynamo.maybe_mark_dynamic(refs_chosen, 0)\n",
    "        torch._dynamo.maybe_mark_dynamic(refs_rejected, 0)\n",
    "        torch._dynamo.maybe_mark_dynamic(targets_chosen, 0)\n",
    "        torch._dynamo.maybe_mark_dynamic(targets_rejected, 0)\n",
    "\n",
    "        get_sum_logprob = torch.compile(get_sum_logprob)\n",
    "        get_sum_logprob_ref = torch.compile(get_sum_logprob_ref)\n",
    "\n",
    "        grad_inputs_chosen, grad_weight_chosen, logprob_inputs_chosen = get_sum_logprob(\n",
    "            inputs_chosen, \n",
    "            targets_chosen, \n",
    "            inputs_weight,\n",
    "            chunk_size=chunk_size,\n",
    "            ignore_index=ignore_index,\n",
    "        )\n",
    "        grad_inputs_rejected, grad_weight_rejected, logprob_inputs_rejected = get_sum_logprob(\n",
    "            inputs_rejected, \n",
    "            targets_rejected, \n",
    "            inputs_weight,\n",
    "            chunk_size=chunk_size,\n",
    "            ignore_index=ignore_index,\n",
    "        )\n",
    "    \n",
    "        logprob_refs_chosen = get_sum_logprob_ref(refs_chosen, targets_chosen, refs_weight)\n",
    "        logprob_refs_rejected = get_sum_logprob_ref(refs_rejected, targets_rejected, refs_weight)\n",
    "\n",
    "        ctx.save_for_backward(\n",
    "            grad_inputs_chosen, \n",
    "            grad_inputs_rejected,\n",
    "            grad_weight_chosen,\n",
    "            grad_weight_rejected,\n",
    "        )\n",
    "        \n",
    "        return logprob_inputs_chosen, logprob_inputs_rejected, logprob_refs_chosen, logprob_refs_rejected\n",
    "\n",
    "    @staticmethod\n",
    "    @torch.no_grad()\n",
    "    def backward(ctx, grad_logprob_chosen, grad_logprob_rejected, grad_logprob_ref_chosen, grad_logprob_ref_rejected):\n",
    "        (\n",
    "            grad_inputs_chosen,\n",
    "            grad_inputs_rejected,\n",
    "            grad_weight_chosen,\n",
    "            grad_weight_rejected,\n",
    "        ) = ctx.saved_tensors\n",
    "\n",
    "        grad_inputs_chosen_out = grad_inputs_chosen * grad_logprob_chosen\n",
    "        grad_inputs_rejected_out = grad_inputs_rejected * grad_logprob_rejected\n",
    "        \n",
    "        # Gradients for inputs_weight (accumulate from both chosen and rejected)\n",
    "        grad_inputs_weight = (\n",
    "            grad_weight_chosen * grad_logprob_chosen + \n",
    "            grad_weight_rejected * grad_logprob_rejected\n",
    "        )\n",
    "        \n",
    "        # Return gradients in same order as forward inputs\n",
    "        # (inputs_chosen, inputs_rejected, refs_chosen, refs_rejected, \n",
    "        #  targets_chosen, targets_rejected, inputs_weight, refs_weight,\n",
    "        #  compiled, chunk_size, ignore_index)\n",
    "        return (\n",
    "            grad_inputs_chosen_out,   # inputs_chosen\n",
    "            grad_inputs_rejected_out, # inputs_rejected\n",
    "            None,                      # refs_chosen (no grad needed - frozen)\n",
    "            None,                      # refs_rejected (no grad needed - frozen)\n",
    "            None,                      # targets_chosen (integer indices)\n",
    "            None,                      # targets_rejected (integer indices)\n",
    "            grad_inputs_weight,        # inputs_weight\n",
    "            None,                      # refs_weight (no grad needed - frozen)\n",
    "            None,                      # compiled\n",
    "            None,                      # chunk_size\n",
    "            None,                      # ignore_index\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ca86971-8cb0-40f7-9ec6-deb40c4558e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory._record_memory_history(\n",
    "   max_entries=100000\n",
    ")\n",
    "\n",
    "# https://huggingface.co/Qwen/Qwen3-32B/blob/main/config.json#L11\n",
    "inputs_chosen = torch.randn(10000, 5120, dtype=torch.bfloat16).cuda()\n",
    "inputs_rejected = torch.randn(5000, 5120, dtype=torch.bfloat16).cuda()\n",
    "refs_chosen = torch.randn(10000, 5120, dtype=torch.bfloat16).cuda()\n",
    "refs_rejected = torch.randn(5000, 5120, dtype=torch.bfloat16).cuda()\n",
    "\n",
    "# https://huggingface.co/Qwen/Qwen3-32B/blob/main/config.json#L29\n",
    "targets_chosen = torch.randint(low=0, high=151936, size=(10000,)).cuda()\n",
    "targets_rejected = torch.randint(low=0, high=151936, size=(5000,)).cuda()\n",
    "\n",
    "# assumed packing 1 sequences\n",
    "# liger divide by batch size // 2\n",
    "num_seqs = 1\n",
    "\n",
    "inputs_weight = torch.nn.Linear(5120, 151936).cuda()\n",
    "refs_weight = torch.nn.Linear(5120, 151936).cuda()\n",
    "\n",
    "out = ChunkedDPO.apply(\n",
    "    inputs_chosen.float(),\n",
    "    inputs_rejected.float(),\n",
    "    refs_chosen.float(),\n",
    "    refs_rejected.float(),\n",
    "    targets_chosen,\n",
    "    targets_rejected,\n",
    "    inputs_weight.weight,\n",
    "    refs_weight.weight,\n",
    ")\n",
    "logpprob_inputs_chosen, logpprob_inputs_rejected, logpprob_refs_chosen, logpprob_refs_rejected = out\n",
    "\n",
    "beta = 0.1\n",
    "chosen_logratios = logpprob_inputs_chosen - logpprob_refs_chosen\n",
    "rejected_logratios = logpprob_inputs_rejected - logpprob_refs_rejected\n",
    "\n",
    "chosen_rewards = beta * chosen_logratios\n",
    "rejected_rewards = beta * rejected_logratios\n",
    "logits_diff = beta * (chosen_logratios - rejected_logratios)\n",
    "loss = -F.logsigmoid(logits_diff) / num_seqs\n",
    "loss.backward()\n",
    "\n",
    "torch.cuda.memory._dump_snapshot(\"chunk-pytorch-v2.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f907c8c7-4c92-4b09-b81b-c20b45418905",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_grad = inputs_weight.weight.grad.clone()\n",
    "inputs_weight.weight.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd900a7-0e2d-462d-9fed-0e7410d92796",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd84ee24-ef80-4547-9bad-9e735aaa9324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from liger_kernel.chunked_loss import LigerFusedLinearDPOLoss\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def pad_dim1(tensors, padding_value=0):\n",
    "    tensors = [t.unsqueeze(0) if t.dim() == 2 else t for t in tensors]\n",
    "\n",
    "    max_len = max(t.shape[1] for t in tensors)\n",
    "\n",
    "    padded = []\n",
    "    for t in tensors:\n",
    "        pad_len = max_len - t.shape[1]\n",
    "        if pad_len > 0:\n",
    "            t = F.pad(t, (0, 0, 0, pad_len), value=padding_value)\n",
    "        padded.append(t)\n",
    "\n",
    "    return torch.cat(padded, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8dffbe-9570-4f6a-974e-c1dec38a0fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = pad_sequence([targets_chosen, targets_rejected], batch_first=True, padding_value=-100).cuda()\n",
    "inputs_padded = pad_dim1([inputs_chosen, inputs_rejected])\n",
    "refs_padded = pad_dim1([refs_chosen, refs_rejected])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd28e4d9-c460-41f4-8168-60422275fba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "liger_loss = LigerFusedLinearDPOLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9938cdaa-941c-4a88-b179-4e7378ad4faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = liger_loss(\n",
    "    inputs_weight.weight,\n",
    "    inputs_padded.to(torch.float32),\n",
    "    targets,\n",
    "    ref_input=refs_padded.to(torch.float32),\n",
    "    ref_weight=refs_weight.weight\n",
    ")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3663c471-c32d-43e4-a1ca-309c47c399b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[0].backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a628e5-2ccb-437c-a858-b91774475e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(loss, out[0], atol=0.125, rtol=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fc6fdb-d253-461d-be87-1a6f7a22cab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(first_grad, inputs_weight.weight.grad, atol=0.125, rtol=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6da0ee9-2d93-47d0-ac4d-0bea58bf3332",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_weight.weight.grad"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multipacking-dpo",
   "language": "python",
   "name": "multipacking-dpo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
