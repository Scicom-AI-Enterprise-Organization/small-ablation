{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88248c9-b3f6-476d-80ec-8566ff020992",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import requests\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import subprocess\n",
    "import signal\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from threading import Thread\n",
    "from queue import Queue\n",
    "from multiprocess import Pool\n",
    "import itertools\n",
    "\n",
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield (l[i: i + n], i // n)\n",
    "\n",
    "def multiprocessing(strings, function, cores=6, returned=True):\n",
    "    df_split = chunks(strings, len(strings) // cores)\n",
    "    pool = Pool(cores)\n",
    "    pooled = pool.map(function, df_split)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    if returned:\n",
    "        return list(itertools.chain(*pooled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c96d614-67f3-4a3f-b57b-42d1fb91241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop(rows):\n",
    "    rows, index = rows\n",
    "\n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(index)\n",
    "    \n",
    "    for row in rows:\n",
    "        model, port, folder = row\n",
    "        os.makedirs(folder, exist_ok = True)\n",
    "        cmd = f'/root/.venv/bin/vllm serve {model} --gpu-memory-utilization 0.95 --port {port}'\n",
    "        process = subprocess.Popen(cmd.split(), stdout=subprocess.DEVNULL, stderr=subprocess.PIPE)\n",
    "        try:\n",
    "            url = f'http://localhost:{port}/docs'\n",
    "            pbar = tqdm(range(1000))\n",
    "            for i in pbar:\n",
    "                try:\n",
    "                    r = requests.get(url, timeout=5.0)\n",
    "                    if r.status_code == 200:\n",
    "                        break\n",
    "                except Exception:\n",
    "                    pass\n",
    "                pbar.set_description(f\"checking health {url} for {i} times\")\n",
    "                time.sleep(5.0)\n",
    "\n",
    "            with open('MalayMMLU_0shot.json') as fopen:\n",
    "                malaymmlu = json.load(fopen)\n",
    "            \n",
    "            questions = []\n",
    "            for i in range(len(malaymmlu)):\n",
    "                q = malaymmlu[i]['prompt']\n",
    "                questions.append((i, q))\n",
    "\n",
    "            def generate_answer(row, repeat = 5):\n",
    "                no, q = row\n",
    "                for k in range(repeat):\n",
    "                    filename = os.path.join(folder, f'{no}-{k}.json')\n",
    "                    try:\n",
    "                        with open(filename) as fopen:\n",
    "                            json.load(fopen)\n",
    "                        continue\n",
    "                    except:\n",
    "                        pass\n",
    "            \n",
    "                    system = 'First, you try to think step-by-step in {{lang}}, after that, put your final answer within $\\\\boxed{}$.'\n",
    "                    messages = [\n",
    "                        {\"role\": \"system\", \"content\": system.replace('{{lang}}', 'malay')},\n",
    "                        {\"role\": \"user\", \"content\": q},\n",
    "                    ]\n",
    "            \n",
    "                    json_data = {\n",
    "                        'model': model,\n",
    "                        'messages': messages,\n",
    "                        'max_tokens': 24000,\n",
    "                    }\n",
    "            \n",
    "                    while True:\n",
    "                        try:\n",
    "                            response = requests.post(f'http://localhost:{port}/v1/chat/completions', json=json_data)\n",
    "                            r = response.json()['choices'][0]['message']['reasoning_content'].strip()\n",
    "                            answers = re.findall(r\"\\$boxed\\{(.*?)\\}\\$\", r)\n",
    "                            if len(answers) == 1:\n",
    "                                a = answers[0]\n",
    "                                with open(filename, 'w') as fopen:\n",
    "                                    json.dump(a, fopen)\n",
    "                                    break\n",
    "                        except:\n",
    "                            pass\n",
    "\n",
    "            def consumer(queue, name):\n",
    "                while True:\n",
    "                    if queue.qsize() == 0:\n",
    "                        break\n",
    "                    item = queue.get()\n",
    "                    generate_answer(item)\n",
    "                print(f'consumer {name} done')\n",
    "            \n",
    "            generate_answer(questions[0])\n",
    "            queue = Queue()\n",
    "            for u in questions:\n",
    "                queue.put(u)\n",
    "                \n",
    "            ori_size = queue.qsize()\n",
    "            max_worker = 30\n",
    "            consumers = [Thread(target=consumer, args=(queue,i)) for i in range(max_worker)]\n",
    "            for i in range(len(consumers)):\n",
    "                consumers[i].start()\n",
    "                \n",
    "            pbar = tqdm(total=ori_size)\n",
    "            last_size = 0\n",
    "            while True:\n",
    "                size = queue.qsize()\n",
    "                if size == 0:\n",
    "                    break\n",
    "                left = ori_size - size\n",
    "                minus = left - last_size\n",
    "                if minus > 0:\n",
    "                    pbar.update(minus)\n",
    "                    last_size += minus\n",
    "            \n",
    "            pbar.close()\n",
    "            \n",
    "        finally:\n",
    "            if process.poll() is None:\n",
    "                print(\"Cleaning up vLLM process...\")\n",
    "                process.send_signal(signal.SIGINT)\n",
    "                try:\n",
    "                    process.wait(timeout=10)\n",
    "                except subprocess.TimeoutExpired:\n",
    "                    print(\"Force killing vLLM process...\")\n",
    "                    process.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85ecb7c-731f-4000-b93e-f0676a8de9ba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rows = [\n",
    "    ['malaysian-reasoning-20b-lora-r16-merged', 8000, 'malaymmlu-20b-r16'],\n",
    "    ['malaysian-reasoning-20b-lora-r32-merged', 8001, 'malaymmlu-20b-r32'],\n",
    "    ['malaysian-reasoning-20b-lora-r64-merged', 8002, 'malaymmlu-20b-r64'],\n",
    "    ['malaysian-reasoning-20b-lora-r128-merged', 8003, 'malaymmlu-20b-r128'],\n",
    "    ['malaysian-reasoning-20b-lora-r256-merged', 8004, 'malaymmlu-20b-r256'],\n",
    "    ['malaysian-reasoning-20b-lora-r512-merged', 8005, 'malaymmlu-20b-r512'],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2db7311-c673-4433-b5db-a5f82b467b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiprocessing(rows, loop, len(rows), returned = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "malaysian-reasoning",
   "language": "python",
   "name": "malaysian-reasoning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
