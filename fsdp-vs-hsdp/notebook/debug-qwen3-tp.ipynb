{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b6b5097-1db7-4eb1-83a1-6b65b0e3f542",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n"
     ]
    }
   ],
   "source": [
    "from multigpus_repl import init_multigpus_repl, multigpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7bdde03-34e2-45e8-9c18-6eed3b776eb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPU 0] Worker 0/8 initialized on GPU 0 on localhost:12355"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Fetching 7 files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 81783.09it/s]\n",
      "Fetching 7 files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 79137.81it/s]\n",
      "You do not have `flash_attn` installed, using `kernels-community/vllm-flash-attn3` from the `kernels` library instead!\n",
      "Fetching 7 files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 84126.44it/s]\n",
      "You do not have `flash_attn` installed, using `kernels-community/vllm-flash-attn3` from the `kernels` library instead!\n",
      "You do not have `flash_attn` installed, using `kernels-community/vllm-flash-attn3` from the `kernels` library instead!\n",
      "Fetching 7 files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 75475.91it/s]\n",
      "Fetching 7 files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 82241.25it/s]\n",
      "You do not have `flash_attn` installed, using `kernels-community/vllm-flash-attn3` from the `kernels` library instead!\n",
      "You do not have `flash_attn` installed, using `kernels-community/vllm-flash-attn3` from the `kernels` library instead!\n",
      "Fetching 7 files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 51150.05it/s]\n",
      "You do not have `flash_attn` installed, using `kernels-community/vllm-flash-attn3` from the `kernels` library instead!\n",
      "Fetching 7 files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 83886.08it/s]\n",
      "You do not have `flash_attn` installed, using `kernels-community/vllm-flash-attn3` from the `kernels` library instead!\n",
      "Fetching 7 files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 81105.33it/s]\n",
      "You do not have `flash_attn` installed, using `kernels-community/vllm-flash-attn3` from the `kernels` library instead!\n",
      "Fetching 7 files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 101241.82it/s]\n",
      "Fetching 7 files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 21477.78it/s]\n",
      "Fetching 7 files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 71961.10it/s]\n",
      "Fetching 7 files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 95325.09it/s]\n",
      "Fetching 7 files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 97541.95it/s]\n",
      "Fetching 7 files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 98194.41it/s]\n",
      "Fetching 7 files: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 107153.75it/s]\n",
      "Fetching 7 files: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:00<00:00, 92911.80it/s]\n"
     ]
    }
   ],
   "source": [
    "init_multigpus_repl(print_on_rank=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebdfab42-ad6e-4e6b-bd53-1c9e306bfd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%multigpus\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from functools import partial\n",
    "from torch.distributed.algorithms._checkpoint.checkpoint_wrapper import (\n",
    "    CheckpointImpl,\n",
    "    apply_activation_checkpointing,\n",
    "    checkpoint_wrapper,\n",
    ")\n",
    "from torch.distributed._tensor import Shard, Replicate\n",
    "from torch.distributed.tensor.parallel import (\n",
    "    parallelize_module,\n",
    "    ColwiseParallel,\n",
    "    RowwiseParallel,\n",
    "    PrepareModuleInput,\n",
    "    SequenceParallel\n",
    ")\n",
    "from torch import distributed as dist\n",
    "from torch.distributed.tensor import distribute_tensor\n",
    "from torch.distributed.device_mesh import init_device_mesh\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.distributed.fsdp import fully_shard, MixedPrecisionPolicy, CPUOffloadPolicy\n",
    "from transformers.models.qwen3.modeling_qwen3 import Qwen3DecoderLayer\n",
    "from streaming import LocalDataset\n",
    "from streaming.base.format.mds.encodings import Encoding, _encodings\n",
    "import numpy as np\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Qwen3ForCausalLM\n",
    "import transformers.models.qwen3.modeling_qwen3 as qwen3_modeling\n",
    "from liger_kernel.transformers import LigerFusedLinearCrossEntropyLoss\n",
    "\n",
    "model_name = \"Qwen/Qwen3-0.6B\"\n",
    "\n",
    "class UInt32(Encoding):\n",
    "    def encode(self, obj) -> bytes:\n",
    "        return obj.tobytes()\n",
    "\n",
    "    def decode(self, data: bytes):\n",
    "        return np.frombuffer(data, np.uint32)\n",
    "\n",
    "_encodings['uint32'] = UInt32\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, folder):\n",
    "        self.dataset = LocalDataset(local=folder)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.dataset[idx]\n",
    "        data.pop('text', None)\n",
    "        data.pop('token_type_ids', None)\n",
    "\n",
    "        for k in data.keys():\n",
    "            data[k] = data[k].astype(np.int64)\n",
    "    \n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "def collator(batch):\n",
    "    batch = [b for b in batch if b is not None]\n",
    "    input_ids = [b['input_ids'] for b in batch]\n",
    "    position_ids = [b['position_ids'] for b in batch]\n",
    "    labels = [b['input_ids'].copy() for b in batch]\n",
    "    attention_mask = [b['attention_mask'] for b in batch]\n",
    "    input_ids = np.concatenate(input_ids)\n",
    "    position_ids = np.concatenate(position_ids)\n",
    "    labels = np.concatenate(labels)\n",
    "    query_lens = np.concatenate(attention_mask)\n",
    "    cumsum = [0] + np.cumsum(query_lens).tolist()\n",
    "    max_cumsum = int(np.max(cumsum))\n",
    "    cu_seq_lens_q = torch.tensor(cumsum, dtype=torch.int32)\n",
    "    cu_seq_lens_k = torch.tensor(cumsum, dtype=torch.int32)\n",
    "    max_seqlen_q = int(np.max(query_lens))\n",
    "    return {\n",
    "        'input_ids': torch.tensor(input_ids)[None],\n",
    "        'position_ids': torch.tensor(position_ids)[None],\n",
    "        'labels': torch.tensor(labels)[None],\n",
    "        'cu_seq_lens_q': cu_seq_lens_q,\n",
    "        'cu_seq_lens_k': cu_seq_lens_k,\n",
    "        'max_length_q': max_seqlen_q,\n",
    "        'max_length_k': max_seqlen_q\n",
    "    }\n",
    "\n",
    "class LinearLoRA(nn.Module):\n",
    "    def __init__(self, linear: nn.Linear, r=4, alpha=1.0):\n",
    "        super().__init__()\n",
    "        self.linear = linear\n",
    "        self.r = r\n",
    "        self.alpha = alpha\n",
    "        self.scaling = alpha / r\n",
    "\n",
    "        in_features = linear.in_features\n",
    "        out_features = linear.out_features\n",
    "        \n",
    "        device = self.linear.weight.device\n",
    "        dtype = self.linear.weight.dtype\n",
    "\n",
    "        self.lora_A = nn.ModuleDict({})\n",
    "        self.lora_B = nn.ModuleDict({})\n",
    "        \n",
    "        self.lora_A['e'] = nn.Linear(\n",
    "            in_features, r, bias=False, \n",
    "            device = device,\n",
    "            dtype = dtype,\n",
    "        )\n",
    "        self.lora_B['e'] = nn.Linear(\n",
    "            r, out_features, bias=False, \n",
    "            device = device,\n",
    "            dtype = dtype,\n",
    "        )\n",
    "\n",
    "        for param in self.lora_A['e'].parameters():\n",
    "            param.requires_grad = True\n",
    "        for param in self.lora_B['e'].parameters():\n",
    "            param.requires_grad = True\n",
    "\n",
    "        # https://github.com/huggingface/peft/blob/main/src/peft/tuners/lora/layer.py#L260\n",
    "        init.kaiming_uniform_(self.lora_A['e'].weight, a=math.sqrt(5))\n",
    "        init.zeros_(self.lora_B['e'].weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        lora_update = self.lora_B['e'](self.lora_A['e'](x.to(self.lora_A['e'].weight.dtype))) * self.scaling\n",
    "        out = out + lora_update.to(x.dtype)\n",
    "        return out\n",
    "\n",
    "class Model(Qwen3ForCausalLM):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.loss = LigerFusedLinearCrossEntropyLoss(reduction=\"mean\")\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask=None, position_ids=None, labels=None, **kwargs):\n",
    "        super_out = self.model.forward(\n",
    "            input_ids = input_ids,\n",
    "            position_ids = position_ids, \n",
    "            attention_mask = attention_mask, \n",
    "            output_hidden_states = True,\n",
    "            **kwargs,\n",
    "        )\n",
    "        if labels is not None:\n",
    "            embeddings = super_out.last_hidden_state\n",
    "            embeddings = embeddings[:,:-1].reshape(-1, embeddings.shape[-1])\n",
    "            labels = labels[..., 1:].contiguous()\n",
    "            labels = labels.reshape(-1)\n",
    "            loss = self.loss(self.lm_head.weight, embeddings, labels)\n",
    "            return {'loss': loss}\n",
    "        return super_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31b01dde-0b5c-41f1-87f1-fb91c6350fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%multigpus\n",
    "\n",
    "device_type = torch.accelerator.current_accelerator()\n",
    "device_mesh = init_device_mesh(device_type.type, (1, 4), mesh_dim_names=(\"dp\", \"tp\"))\n",
    "tp_mesh = device_mesh[\"tp\"]\n",
    "dp_mesh = device_mesh[\"dp\"]\n",
    "dp_rank = dp_mesh.get_local_rank()\n",
    "dp_world_size = dp_mesh.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c0502db-6f06-4ba2-b571-08eb47d9e292",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%multigpus\n",
    "\n",
    "dataset = Dataset('multipacking')\n",
    "sampler = DistributedSampler(\n",
    "    dataset,\n",
    "    num_replicas=dp_world_size,\n",
    "    rank=dp_rank,\n",
    "    shuffle=True,\n",
    ")\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset,\n",
    "    batch_size=5,\n",
    "    sampler=sampler,\n",
    "    num_workers=5,\n",
    "    prefetch_factor=5,\n",
    "    pin_memory=True,\n",
    "    collate_fn=collator,\n",
    ")\n",
    "iter_train_loader = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95128659-3de5-4951-addf-3ed2a9c10d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%multigpus\n",
    "\n",
    "model = Model.from_pretrained(\n",
    "    model_name, \n",
    "    attn_implementation='flash_attention_3',\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "selected = [\n",
    "    \"q_proj\", \n",
    "    \"k_proj\", \n",
    "    \"v_proj\", \n",
    "    \"o_proj\",\n",
    "    \"gate_proj\",\n",
    "    \"up_proj\",\n",
    "    \"down_proj\"\n",
    "]\n",
    "for name, module in model.named_modules():\n",
    "    for child_name, child in module.named_children():\n",
    "        if len(child_name) and any([a in child_name for a in selected]) and isinstance(child, nn.Linear):\n",
    "            lora = LinearLoRA(child, r=128, alpha=256)\n",
    "            setattr(module, child_name, lora)\n",
    "\n",
    "# model.model = parallelize_module(\n",
    "#     model.model,\n",
    "#     tp_mesh,\n",
    "#     {\n",
    "#         \"embed_tokens\": ColwiseParallel(\n",
    "#             input_layouts=Replicate(),\n",
    "#             output_layouts=Replicate(),\n",
    "#         ),\n",
    "#         \"norm\": SequenceParallel(),\n",
    "#     }\n",
    "# )\n",
    "\n",
    "for layer_id, block in enumerate(model.model.layers):\n",
    "    layer_tp_plan = {\n",
    "\n",
    "        # \"input_layernorm\": SequenceParallel(),\n",
    "        # \"post_attention_layernorm\": SequenceParallel(),\n",
    "\n",
    "        \"self_attn.q_proj.linear\": ColwiseParallel(),\n",
    "        \"self_attn.q_proj.lora_A.e\": RowwiseParallel(input_layouts=Replicate()),\n",
    "        \"self_attn.q_proj.lora_B.e\": ColwiseParallel(),   \n",
    "\n",
    "        \"self_attn.k_proj.linear\": ColwiseParallel(),\n",
    "        \"self_attn.k_proj.lora_A.e\": RowwiseParallel(input_layouts=Replicate()),\n",
    "        \"self_attn.k_proj.lora_B.e\": ColwiseParallel(),\n",
    "\n",
    "        \"self_attn.v_proj.linear\": ColwiseParallel(),\n",
    "        \"self_attn.v_proj.lora_A.e\": RowwiseParallel(input_layouts=Replicate()),\n",
    "        \"self_attn.v_proj.lora_B.e\": ColwiseParallel(),\n",
    "\n",
    "        \"self_attn.o_proj.linear\": RowwiseParallel(),\n",
    "        \"self_attn.o_proj.lora_A.e\": RowwiseParallel(),\n",
    "        # \"self_attn.o_proj.lora_B.e\": RowwiseParallel(),\n",
    "\n",
    "        \"mlp.gate_proj.linear\": ColwiseParallel(),\n",
    "        \"mlp.gate_proj.lora_A.e\": RowwiseParallel(input_layouts=Replicate()),\n",
    "        \"mlp.gate_proj.lora_B.e\": ColwiseParallel(),\n",
    "\n",
    "        \"mlp.up_proj.linear\": ColwiseParallel(),\n",
    "        \"mlp.up_proj.lora_A.e\": RowwiseParallel(input_layouts=Replicate()),\n",
    "        \"mlp.up_proj.lora_B.e\": ColwiseParallel(),\n",
    "\n",
    "        \"mlp.down_proj.linear\": RowwiseParallel(),\n",
    "        \"mlp.down_proj.lora_A.e\": RowwiseParallel(),\n",
    "        # \"mlp.down_proj.lora_B.e\": RowwiseParallel(),\n",
    "    }\n",
    "    parallelize_module(\n",
    "        module=block,\n",
    "        device_mesh=tp_mesh,\n",
    "        parallelize_plan=layer_tp_plan\n",
    "    )\n",
    "    \n",
    "device = torch.device(f\"{device_type}:{rank}\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4187f34-de12-4898-ab00-e789c446adf4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%multigpus\n",
    "\n",
    "b = next(iter_train_loader)\n",
    "for k in b.keys():\n",
    "    if isinstance(b[k], torch.Tensor):\n",
    "        b[k] = b[k].to(device, non_blocking=True)\n",
    "\n",
    "out = model(**b, use_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "879f4745-4c8a-4f0e-8e6a-8d690c2db84a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPU 0] {'loss': tensor(3.3200, device='cuda:0',\n",
      "       grad_fn=<LigerFusedLinearCrossEntropyFunctionBackward>)}\n"
     ]
    }
   ],
   "source": [
    "%%multigpus\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a6f088-e2a6-4e2a-bf97-f8d7fcbd3685",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "malaysian-reasoning",
   "language": "python",
   "name": "malaysian-reasoning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
