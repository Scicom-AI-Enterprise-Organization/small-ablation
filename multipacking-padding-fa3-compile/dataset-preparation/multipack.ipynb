{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acb93de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import snapshot_download\n",
    "\n",
    "# snapshot_download(\n",
    "#     repo_id=\"malaysia-ai/Multilingual-TTS\", \n",
    "#     repo_type=\"dataset\",\n",
    "#     allow_patterns=\"*/*.parquet\",\n",
    "#     local_dir=\"./Multilingual-TTS\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58f9a9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/asr-training/finetune-whisper/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import torch\n",
    "import IPython.display as ipd\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "from transformers import AutoTokenizer, AddedToken\n",
    "from streaming import MDSWriter\n",
    "from streaming.base.format.mds.encodings import Encoding, _encodings\n",
    "from streaming import LocalDataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from multiprocess import Pool\n",
    "import itertools\n",
    "\n",
    "def chunks(l, n):\n",
    "    for i in range(0, len(l), n):\n",
    "        yield (l[i: i + n], i // n)\n",
    "\n",
    "def multiprocessing(strings, function, cores=6, returned=True):\n",
    "    df_split = chunks(strings, len(strings) // cores)\n",
    "    pool = Pool(cores)\n",
    "    pooled = pool.map(function, df_split)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "\n",
    "    if returned:\n",
    "        return list(itertools.chain(*pooled))\n",
    "\n",
    "class UInt32(Encoding):\n",
    "    def encode(self, obj) -> bytes:\n",
    "        return obj.tobytes()\n",
    "\n",
    "    def decode(self, data: bytes):\n",
    "        return np.frombuffer(data, np.uint32)\n",
    "\n",
    "_encodings['uint32'] = UInt32\n",
    "\n",
    "columns = {\n",
    "    'input_ids': 'uint32',\n",
    "    'position_ids': 'uint32',\n",
    "    'attention_mask': 'uint32',\n",
    "    'audio': 'str',\n",
    "    'text': 'str'\n",
    "}\n",
    "hashes = 'sha1', 'xxh64'\n",
    "\n",
    "def new_path(f):\n",
    "    splitted = f.split('/')\n",
    "    folder = f.split('/')[0]\n",
    "    folder = folder + '_neucodec'\n",
    "    new_f = os.path.join(folder, '/'.join(splitted[1:]))\n",
    "    new_f = new_f.replace('.mp3', '.json').replace('.wav', '.json')\n",
    "    return new_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d222b16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop(files):\n",
    "    files, _ = files\n",
    "    data = []\n",
    "    for f in tqdm(files):\n",
    "        df = pd.read_parquet(f).to_dict(orient = 'records')\n",
    "        for i in range(len(df)):\n",
    "            token_filename = new_path(df[i]['audio_filename'])\n",
    "            if not os.path.exists(token_filename):\n",
    "                continue\n",
    "            df[i]['token_filename'] = token_filename\n",
    "            data.append(df[i])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d952d116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.34s/it]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.44s/it]\n",
      "100%|██████████| 2/2 [00:03<00:00,  1.91s/it]\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.09s/it]\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.92it/s]\n",
      "100%|██████████| 2/2 [00:04<00:00,  2.38s/it]\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.37s/it]\n",
      "100%|██████████| 2/2 [00:02<00:00,  1.35s/it]\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.59s/it]\n",
      "100%|██████████| 2/2 [00:07<00:00,  3.73s/it]\n",
      "100%|██████████| 2/2 [00:00<00:00,  9.57it/s]\n",
      "\n",
      "100%|██████████| 2/2 [00:08<00:00,  4.42s/it]\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.51s/it]\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.54s/it]\n",
      "100%|██████████| 2/2 [00:00<00:00,  2.23it/s]\n",
      "100%|██████████| 2/2 [00:09<00:00,  4.78s/it]\n",
      "100%|██████████| 2/2 [00:10<00:00,  5.08s/it]\n",
      "100%|██████████| 2/2 [00:10<00:00,  5.38s/it]\n",
      "100%|██████████| 2/2 [00:11<00:00,  5.56s/it]\n",
      "100%|██████████| 2/2 [00:11<00:00,  5.60s/it]\n",
      "100%|██████████| 2/2 [00:11<00:00,  5.71s/it]\n",
      "100%|██████████| 2/2 [00:11<00:00,  5.79s/it]\n",
      "100%|██████████| 2/2 [00:12<00:00,  6.14s/it]\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.89s/it]\n",
      "100%|██████████| 2/2 [00:06<00:00,  3.09s/it]\n",
      "100%|██████████| 2/2 [00:15<00:00,  7.55s/it]\n",
      "100%|██████████| 2/2 [00:13<00:00,  6.76s/it]\n",
      "100%|██████████| 2/2 [00:18<00:00,  9.41s/it]\n",
      "100%|██████████| 2/2 [00:19<00:00,  9.99s/it]\n",
      "100%|██████████| 2/2 [00:17<00:00,  8.54s/it]\n",
      "100%|██████████| 2/2 [00:22<00:00, 11.32s/it]\n",
      "100%|██████████| 2/2 [00:28<00:00, 14.03s/it]\n",
      "100%|██████████| 2/2 [00:31<00:00, 15.67s/it]\n",
      "100%|██████████| 2/2 [00:33<00:00, 16.53s/it]\n",
      "100%|██████████| 2/2 [00:33<00:00, 16.71s/it]\n",
      "100%|██████████| 2/2 [00:31<00:00, 15.99s/it]\n",
      "100%|██████████| 2/2 [00:53<00:00, 26.82s/it]\n",
      "100%|██████████| 2/2 [01:03<00:00, 31.71s/it]\n",
      "100%|██████████| 2/2 [01:17<00:00, 38.62s/it]\n",
      "100%|██████████| 2/2 [01:41<00:00, 50.93s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17871888"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob('Multilingual-TTS/*/*.parquet')\n",
    "files = [f for f in files if 'Malaysian-TTS-v2' not in f]\n",
    "data = multiprocessing(files, loop, cores = 30)\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c1f4c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "malaysian = pd.read_parquet('Multilingual-TTS/Malaysian-TTS-v2/train-00000-of-00001.parquet').to_dict(orient = 'records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cee8b368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65537"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('Qwen/Qwen3-1.7B-Base')\n",
    "extra = [AddedToken('<|speech_start|>')]\n",
    "for i in range(65536):\n",
    "    extra.append(AddedToken(f'<|s_{i}|>'))\n",
    "tokenizer.add_tokens(extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7736aff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio_filename': 'ORAA-MUPE-ASR_audio/ORAA-MUPE-ASR-data-train-00044-of-00074_0.mp3',\n",
       " 'text': 'Tchan, tchan, tchan, tchan.',\n",
       " 'speaker': 'ORAA-MUPE-ASR_audio_MA_HV186',\n",
       " 'token_filename': 'ORAA-MUPE-ASR_audio_neucodec/ORAA-MUPE-ASR-data-train-00044-of-00074_0.json'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac78c657",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = {\n",
    "    'input_ids': 'uint32',\n",
    "}\n",
    "\n",
    "def loop(rows):\n",
    "    rows, index = rows\n",
    "    out_root = f'tokenized-4k-qwen3/tokenized-{index}'\n",
    "    os.system(f'rm -rf {out_root}')\n",
    "    with MDSWriter(out=out_root, columns=columns, compression=None, hashes=hashes) as out:\n",
    "        for row in tqdm(rows):\n",
    "\n",
    "            text = row['text']\n",
    "            \n",
    "            try:\n",
    "                with open(row['token_filename']) as fopen:\n",
    "                    token = json.load(fopen)\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            if len(text.split()) > len(token):\n",
    "                continue\n",
    "\n",
    "            left = row['speaker'] +': ' + text\n",
    "            \n",
    "            token = ''.join([f'<|s_{t}|>' for t in token])\n",
    "            prompt = f'<|im_start|>{left}<|speech_start|>{token}<|im_end|>'\n",
    "            \n",
    "            outputs = tokenizer(prompt, add_special_tokens = False)\n",
    "            input_ids = outputs['input_ids']\n",
    "            input_ids = np.array(input_ids).astype(np.uint32)\n",
    "\n",
    "            out.write({\n",
    "                'input_ids': input_ids,\n",
    "            })\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84ff67d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = data + malaysian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d74f7f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 1405.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': array([151644,    868,   6029,   5251,     52,   1740,     12,   1911,\n",
       "            49,  29688,  85311,   2039,     53,     16,     23,     21,\n",
       "            25,    350,   5658,     11,    259,   5658,     11,    259,\n",
       "          5658,     11,    259,   5658,     13, 151669, 192623, 203889,\n",
       "        204262, 204040, 207452, 208679, 207405, 206385, 208296, 191069,\n",
       "        191628, 208186, 206095, 207422, 212668, 206024, 206155, 206043,\n",
       "        207100, 207116, 205976, 194860, 190700, 192801, 174381, 203002,\n",
       "        190882, 189855, 206728, 185211, 188483, 168478, 190142, 174920,\n",
       "        210075, 206515, 176531, 190460, 152255, 186878, 205775, 158540,\n",
       "        207384, 210167, 211636, 193935, 178120, 168844, 204862, 184823,\n",
       "        207866, 168951, 172121, 212763, 203303, 208471, 215608, 210356,\n",
       "        193184, 157092, 193683, 200924, 173784, 198986, 176701, 171774,\n",
       "        199388, 159174, 153356, 154366, 198416, 158203, 170704, 200190,\n",
       "        178956, 170747, 170494, 199368, 178427, 171020, 195323, 199644,\n",
       "        170491, 199692, 195067, 169992, 187899, 179976, 199943, 200456,\n",
       "        190987, 188428, 200251, 196652, 211727, 216858, 212587, 215654,\n",
       "        215914, 151645], dtype=uint32)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loop((combined[:10], 0))\n",
    "dataset = LocalDataset('tokenized-4k-qwen3/tokenized-0')\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8722d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "  2%|▏         | 7369/464077 [01:45<2:11:59, 57.67it/s]] "
     ]
    }
   ],
   "source": [
    "multiprocessing(combined, loop, cores = 40, returned = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "finetune-whisper",
   "language": "python",
   "name": "finetune-whisper"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
