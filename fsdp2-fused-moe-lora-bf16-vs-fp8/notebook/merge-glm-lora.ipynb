{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e656041-8e11-493e-8bf7-e2a5b3231fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/root/.venv/lib/python3.12/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "Skipping import of cpp extensions due to incompatible torch version 2.9.0+cu128 for torchao version 0.15.0             Please see https://github.com/pytorch/ao/issues/2919 for more info\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "Loading checkpoint shards: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 47/47 [00:37<00:00,  1.24it/s]\n",
      "Some weights of the model checkpoint at ramdisk/GLM-4.5-Air were not used when initializing Glm4MoeForCausalLM: ['model.layers.46.eh_proj.weight', 'model.layers.46.embed_tokens.weight', 'model.layers.46.enorm.weight', 'model.layers.46.hnorm.weight', 'model.layers.46.input_layernorm.weight', 'model.layers.46.mlp.experts.0.down_proj.weight', 'model.layers.46.mlp.experts.0.gate_proj.weight', 'model.layers.46.mlp.experts.0.up_proj.weight', 'model.layers.46.mlp.experts.1.down_proj.weight', 'model.layers.46.mlp.experts.1.gate_proj.weight', 'model.layers.46.mlp.experts.1.up_proj.weight', 'model.layers.46.mlp.experts.10.down_proj.weight', 'model.layers.46.mlp.experts.10.gate_proj.weight', 'model.layers.46.mlp.experts.10.up_proj.weight', 'model.layers.46.mlp.experts.100.down_proj.weight', 'model.layers.46.mlp.experts.100.gate_proj.weight', 'model.layers.46.mlp.experts.100.up_proj.weight', 'model.layers.46.mlp.experts.101.down_proj.weight', 'model.layers.46.mlp.experts.101.gate_proj.weight', 'model.layers.46.mlp.experts.101.up_proj.weight', 'model.layers.46.mlp.experts.102.down_proj.weight', 'model.layers.46.mlp.experts.102.gate_proj.weight', 'model.layers.46.mlp.experts.102.up_proj.weight', 'model.layers.46.mlp.experts.103.down_proj.weight', 'model.layers.46.mlp.experts.103.gate_proj.weight', 'model.layers.46.mlp.experts.103.up_proj.weight', 'model.layers.46.mlp.experts.104.down_proj.weight', 'model.layers.46.mlp.experts.104.gate_proj.weight', 'model.layers.46.mlp.experts.104.up_proj.weight', 'model.layers.46.mlp.experts.105.down_proj.weight', 'model.layers.46.mlp.experts.105.gate_proj.weight', 'model.layers.46.mlp.experts.105.up_proj.weight', 'model.layers.46.mlp.experts.106.down_proj.weight', 'model.layers.46.mlp.experts.106.gate_proj.weight', 'model.layers.46.mlp.experts.106.up_proj.weight', 'model.layers.46.mlp.experts.107.down_proj.weight', 'model.layers.46.mlp.experts.107.gate_proj.weight', 'model.layers.46.mlp.experts.107.up_proj.weight', 'model.layers.46.mlp.experts.108.down_proj.weight', 'model.layers.46.mlp.experts.108.gate_proj.weight', 'model.layers.46.mlp.experts.108.up_proj.weight', 'model.layers.46.mlp.experts.109.down_proj.weight', 'model.layers.46.mlp.experts.109.gate_proj.weight', 'model.layers.46.mlp.experts.109.up_proj.weight', 'model.layers.46.mlp.experts.11.down_proj.weight', 'model.layers.46.mlp.experts.11.gate_proj.weight', 'model.layers.46.mlp.experts.11.up_proj.weight', 'model.layers.46.mlp.experts.110.down_proj.weight', 'model.layers.46.mlp.experts.110.gate_proj.weight', 'model.layers.46.mlp.experts.110.up_proj.weight', 'model.layers.46.mlp.experts.111.down_proj.weight', 'model.layers.46.mlp.experts.111.gate_proj.weight', 'model.layers.46.mlp.experts.111.up_proj.weight', 'model.layers.46.mlp.experts.112.down_proj.weight', 'model.layers.46.mlp.experts.112.gate_proj.weight', 'model.layers.46.mlp.experts.112.up_proj.weight', 'model.layers.46.mlp.experts.113.down_proj.weight', 'model.layers.46.mlp.experts.113.gate_proj.weight', 'model.layers.46.mlp.experts.113.up_proj.weight', 'model.layers.46.mlp.experts.114.down_proj.weight', 'model.layers.46.mlp.experts.114.gate_proj.weight', 'model.layers.46.mlp.experts.114.up_proj.weight', 'model.layers.46.mlp.experts.115.down_proj.weight', 'model.layers.46.mlp.experts.115.gate_proj.weight', 'model.layers.46.mlp.experts.115.up_proj.weight', 'model.layers.46.mlp.experts.116.down_proj.weight', 'model.layers.46.mlp.experts.116.gate_proj.weight', 'model.layers.46.mlp.experts.116.up_proj.weight', 'model.layers.46.mlp.experts.117.down_proj.weight', 'model.layers.46.mlp.experts.117.gate_proj.weight', 'model.layers.46.mlp.experts.117.up_proj.weight', 'model.layers.46.mlp.experts.118.down_proj.weight', 'model.layers.46.mlp.experts.118.gate_proj.weight', 'model.layers.46.mlp.experts.118.up_proj.weight', 'model.layers.46.mlp.experts.119.down_proj.weight', 'model.layers.46.mlp.experts.119.gate_proj.weight', 'model.layers.46.mlp.experts.119.up_proj.weight', 'model.layers.46.mlp.experts.12.down_proj.weight', 'model.layers.46.mlp.experts.12.gate_proj.weight', 'model.layers.46.mlp.experts.12.up_proj.weight', 'model.layers.46.mlp.experts.120.down_proj.weight', 'model.layers.46.mlp.experts.120.gate_proj.weight', 'model.layers.46.mlp.experts.120.up_proj.weight', 'model.layers.46.mlp.experts.121.down_proj.weight', 'model.layers.46.mlp.experts.121.gate_proj.weight', 'model.layers.46.mlp.experts.121.up_proj.weight', 'model.layers.46.mlp.experts.122.down_proj.weight', 'model.layers.46.mlp.experts.122.gate_proj.weight', 'model.layers.46.mlp.experts.122.up_proj.weight', 'model.layers.46.mlp.experts.123.down_proj.weight', 'model.layers.46.mlp.experts.123.gate_proj.weight', 'model.layers.46.mlp.experts.123.up_proj.weight', 'model.layers.46.mlp.experts.124.down_proj.weight', 'model.layers.46.mlp.experts.124.gate_proj.weight', 'model.layers.46.mlp.experts.124.up_proj.weight', 'model.layers.46.mlp.experts.125.down_proj.weight', 'model.layers.46.mlp.experts.125.gate_proj.weight', 'model.layers.46.mlp.experts.125.up_proj.weight', 'model.layers.46.mlp.experts.126.down_proj.weight', 'model.layers.46.mlp.experts.126.gate_proj.weight', 'model.layers.46.mlp.experts.126.up_proj.weight', 'model.layers.46.mlp.experts.127.down_proj.weight', 'model.layers.46.mlp.experts.127.gate_proj.weight', 'model.layers.46.mlp.experts.127.up_proj.weight', 'model.layers.46.mlp.experts.13.down_proj.weight', 'model.layers.46.mlp.experts.13.gate_proj.weight', 'model.layers.46.mlp.experts.13.up_proj.weight', 'model.layers.46.mlp.experts.14.down_proj.weight', 'model.layers.46.mlp.experts.14.gate_proj.weight', 'model.layers.46.mlp.experts.14.up_proj.weight', 'model.layers.46.mlp.experts.15.down_proj.weight', 'model.layers.46.mlp.experts.15.gate_proj.weight', 'model.layers.46.mlp.experts.15.up_proj.weight', 'model.layers.46.mlp.experts.16.down_proj.weight', 'model.layers.46.mlp.experts.16.gate_proj.weight', 'model.layers.46.mlp.experts.16.up_proj.weight', 'model.layers.46.mlp.experts.17.down_proj.weight', 'model.layers.46.mlp.experts.17.gate_proj.weight', 'model.layers.46.mlp.experts.17.up_proj.weight', 'model.layers.46.mlp.experts.18.down_proj.weight', 'model.layers.46.mlp.experts.18.gate_proj.weight', 'model.layers.46.mlp.experts.18.up_proj.weight', 'model.layers.46.mlp.experts.19.down_proj.weight', 'model.layers.46.mlp.experts.19.gate_proj.weight', 'model.layers.46.mlp.experts.19.up_proj.weight', 'model.layers.46.mlp.experts.2.down_proj.weight', 'model.layers.46.mlp.experts.2.gate_proj.weight', 'model.layers.46.mlp.experts.2.up_proj.weight', 'model.layers.46.mlp.experts.20.down_proj.weight', 'model.layers.46.mlp.experts.20.gate_proj.weight', 'model.layers.46.mlp.experts.20.up_proj.weight', 'model.layers.46.mlp.experts.21.down_proj.weight', 'model.layers.46.mlp.experts.21.gate_proj.weight', 'model.layers.46.mlp.experts.21.up_proj.weight', 'model.layers.46.mlp.experts.22.down_proj.weight', 'model.layers.46.mlp.experts.22.gate_proj.weight', 'model.layers.46.mlp.experts.22.up_proj.weight', 'model.layers.46.mlp.experts.23.down_proj.weight', 'model.layers.46.mlp.experts.23.gate_proj.weight', 'model.layers.46.mlp.experts.23.up_proj.weight', 'model.layers.46.mlp.experts.24.down_proj.weight', 'model.layers.46.mlp.experts.24.gate_proj.weight', 'model.layers.46.mlp.experts.24.up_proj.weight', 'model.layers.46.mlp.experts.25.down_proj.weight', 'model.layers.46.mlp.experts.25.gate_proj.weight', 'model.layers.46.mlp.experts.25.up_proj.weight', 'model.layers.46.mlp.experts.26.down_proj.weight', 'model.layers.46.mlp.experts.26.gate_proj.weight', 'model.layers.46.mlp.experts.26.up_proj.weight', 'model.layers.46.mlp.experts.27.down_proj.weight', 'model.layers.46.mlp.experts.27.gate_proj.weight', 'model.layers.46.mlp.experts.27.up_proj.weight', 'model.layers.46.mlp.experts.28.down_proj.weight', 'model.layers.46.mlp.experts.28.gate_proj.weight', 'model.layers.46.mlp.experts.28.up_proj.weight', 'model.layers.46.mlp.experts.29.down_proj.weight', 'model.layers.46.mlp.experts.29.gate_proj.weight', 'model.layers.46.mlp.experts.29.up_proj.weight', 'model.layers.46.mlp.experts.3.down_proj.weight', 'model.layers.46.mlp.experts.3.gate_proj.weight', 'model.layers.46.mlp.experts.3.up_proj.weight', 'model.layers.46.mlp.experts.30.down_proj.weight', 'model.layers.46.mlp.experts.30.gate_proj.weight', 'model.layers.46.mlp.experts.30.up_proj.weight', 'model.layers.46.mlp.experts.31.down_proj.weight', 'model.layers.46.mlp.experts.31.gate_proj.weight', 'model.layers.46.mlp.experts.31.up_proj.weight', 'model.layers.46.mlp.experts.32.down_proj.weight', 'model.layers.46.mlp.experts.32.gate_proj.weight', 'model.layers.46.mlp.experts.32.up_proj.weight', 'model.layers.46.mlp.experts.33.down_proj.weight', 'model.layers.46.mlp.experts.33.gate_proj.weight', 'model.layers.46.mlp.experts.33.up_proj.weight', 'model.layers.46.mlp.experts.34.down_proj.weight', 'model.layers.46.mlp.experts.34.gate_proj.weight', 'model.layers.46.mlp.experts.34.up_proj.weight', 'model.layers.46.mlp.experts.35.down_proj.weight', 'model.layers.46.mlp.experts.35.gate_proj.weight', 'model.layers.46.mlp.experts.35.up_proj.weight', 'model.layers.46.mlp.experts.36.down_proj.weight', 'model.layers.46.mlp.experts.36.gate_proj.weight', 'model.layers.46.mlp.experts.36.up_proj.weight', 'model.layers.46.mlp.experts.37.down_proj.weight', 'model.layers.46.mlp.experts.37.gate_proj.weight', 'model.layers.46.mlp.experts.37.up_proj.weight', 'model.layers.46.mlp.experts.38.down_proj.weight', 'model.layers.46.mlp.experts.38.gate_proj.weight', 'model.layers.46.mlp.experts.38.up_proj.weight', 'model.layers.46.mlp.experts.39.down_proj.weight', 'model.layers.46.mlp.experts.39.gate_proj.weight', 'model.layers.46.mlp.experts.39.up_proj.weight', 'model.layers.46.mlp.experts.4.down_proj.weight', 'model.layers.46.mlp.experts.4.gate_proj.weight', 'model.layers.46.mlp.experts.4.up_proj.weight', 'model.layers.46.mlp.experts.40.down_proj.weight', 'model.layers.46.mlp.experts.40.gate_proj.weight', 'model.layers.46.mlp.experts.40.up_proj.weight', 'model.layers.46.mlp.experts.41.down_proj.weight', 'model.layers.46.mlp.experts.41.gate_proj.weight', 'model.layers.46.mlp.experts.41.up_proj.weight', 'model.layers.46.mlp.experts.42.down_proj.weight', 'model.layers.46.mlp.experts.42.gate_proj.weight', 'model.layers.46.mlp.experts.42.up_proj.weight', 'model.layers.46.mlp.experts.43.down_proj.weight', 'model.layers.46.mlp.experts.43.gate_proj.weight', 'model.layers.46.mlp.experts.43.up_proj.weight', 'model.layers.46.mlp.experts.44.down_proj.weight', 'model.layers.46.mlp.experts.44.gate_proj.weight', 'model.layers.46.mlp.experts.44.up_proj.weight', 'model.layers.46.mlp.experts.45.down_proj.weight', 'model.layers.46.mlp.experts.45.gate_proj.weight', 'model.layers.46.mlp.experts.45.up_proj.weight', 'model.layers.46.mlp.experts.46.down_proj.weight', 'model.layers.46.mlp.experts.46.gate_proj.weight', 'model.layers.46.mlp.experts.46.up_proj.weight', 'model.layers.46.mlp.experts.47.down_proj.weight', 'model.layers.46.mlp.experts.47.gate_proj.weight', 'model.layers.46.mlp.experts.47.up_proj.weight', 'model.layers.46.mlp.experts.48.down_proj.weight', 'model.layers.46.mlp.experts.48.gate_proj.weight', 'model.layers.46.mlp.experts.48.up_proj.weight', 'model.layers.46.mlp.experts.49.down_proj.weight', 'model.layers.46.mlp.experts.49.gate_proj.weight', 'model.layers.46.mlp.experts.49.up_proj.weight', 'model.layers.46.mlp.experts.5.down_proj.weight', 'model.layers.46.mlp.experts.5.gate_proj.weight', 'model.layers.46.mlp.experts.5.up_proj.weight', 'model.layers.46.mlp.experts.50.down_proj.weight', 'model.layers.46.mlp.experts.50.gate_proj.weight', 'model.layers.46.mlp.experts.50.up_proj.weight', 'model.layers.46.mlp.experts.51.down_proj.weight', 'model.layers.46.mlp.experts.51.gate_proj.weight', 'model.layers.46.mlp.experts.51.up_proj.weight', 'model.layers.46.mlp.experts.52.down_proj.weight', 'model.layers.46.mlp.experts.52.gate_proj.weight', 'model.layers.46.mlp.experts.52.up_proj.weight', 'model.layers.46.mlp.experts.53.down_proj.weight', 'model.layers.46.mlp.experts.53.gate_proj.weight', 'model.layers.46.mlp.experts.53.up_proj.weight', 'model.layers.46.mlp.experts.54.down_proj.weight', 'model.layers.46.mlp.experts.54.gate_proj.weight', 'model.layers.46.mlp.experts.54.up_proj.weight', 'model.layers.46.mlp.experts.55.down_proj.weight', 'model.layers.46.mlp.experts.55.gate_proj.weight', 'model.layers.46.mlp.experts.55.up_proj.weight', 'model.layers.46.mlp.experts.56.down_proj.weight', 'model.layers.46.mlp.experts.56.gate_proj.weight', 'model.layers.46.mlp.experts.56.up_proj.weight', 'model.layers.46.mlp.experts.57.down_proj.weight', 'model.layers.46.mlp.experts.57.gate_proj.weight', 'model.layers.46.mlp.experts.57.up_proj.weight', 'model.layers.46.mlp.experts.58.down_proj.weight', 'model.layers.46.mlp.experts.58.gate_proj.weight', 'model.layers.46.mlp.experts.58.up_proj.weight', 'model.layers.46.mlp.experts.59.down_proj.weight', 'model.layers.46.mlp.experts.59.gate_proj.weight', 'model.layers.46.mlp.experts.59.up_proj.weight', 'model.layers.46.mlp.experts.6.down_proj.weight', 'model.layers.46.mlp.experts.6.gate_proj.weight', 'model.layers.46.mlp.experts.6.up_proj.weight', 'model.layers.46.mlp.experts.60.down_proj.weight', 'model.layers.46.mlp.experts.60.gate_proj.weight', 'model.layers.46.mlp.experts.60.up_proj.weight', 'model.layers.46.mlp.experts.61.down_proj.weight', 'model.layers.46.mlp.experts.61.gate_proj.weight', 'model.layers.46.mlp.experts.61.up_proj.weight', 'model.layers.46.mlp.experts.62.down_proj.weight', 'model.layers.46.mlp.experts.62.gate_proj.weight', 'model.layers.46.mlp.experts.62.up_proj.weight', 'model.layers.46.mlp.experts.63.down_proj.weight', 'model.layers.46.mlp.experts.63.gate_proj.weight', 'model.layers.46.mlp.experts.63.up_proj.weight', 'model.layers.46.mlp.experts.64.down_proj.weight', 'model.layers.46.mlp.experts.64.gate_proj.weight', 'model.layers.46.mlp.experts.64.up_proj.weight', 'model.layers.46.mlp.experts.65.down_proj.weight', 'model.layers.46.mlp.experts.65.gate_proj.weight', 'model.layers.46.mlp.experts.65.up_proj.weight', 'model.layers.46.mlp.experts.66.down_proj.weight', 'model.layers.46.mlp.experts.66.gate_proj.weight', 'model.layers.46.mlp.experts.66.up_proj.weight', 'model.layers.46.mlp.experts.67.down_proj.weight', 'model.layers.46.mlp.experts.67.gate_proj.weight', 'model.layers.46.mlp.experts.67.up_proj.weight', 'model.layers.46.mlp.experts.68.down_proj.weight', 'model.layers.46.mlp.experts.68.gate_proj.weight', 'model.layers.46.mlp.experts.68.up_proj.weight', 'model.layers.46.mlp.experts.69.down_proj.weight', 'model.layers.46.mlp.experts.69.gate_proj.weight', 'model.layers.46.mlp.experts.69.up_proj.weight', 'model.layers.46.mlp.experts.7.down_proj.weight', 'model.layers.46.mlp.experts.7.gate_proj.weight', 'model.layers.46.mlp.experts.7.up_proj.weight', 'model.layers.46.mlp.experts.70.down_proj.weight', 'model.layers.46.mlp.experts.70.gate_proj.weight', 'model.layers.46.mlp.experts.70.up_proj.weight', 'model.layers.46.mlp.experts.71.down_proj.weight', 'model.layers.46.mlp.experts.71.gate_proj.weight', 'model.layers.46.mlp.experts.71.up_proj.weight', 'model.layers.46.mlp.experts.72.down_proj.weight', 'model.layers.46.mlp.experts.72.gate_proj.weight', 'model.layers.46.mlp.experts.72.up_proj.weight', 'model.layers.46.mlp.experts.73.down_proj.weight', 'model.layers.46.mlp.experts.73.gate_proj.weight', 'model.layers.46.mlp.experts.73.up_proj.weight', 'model.layers.46.mlp.experts.74.down_proj.weight', 'model.layers.46.mlp.experts.74.gate_proj.weight', 'model.layers.46.mlp.experts.74.up_proj.weight', 'model.layers.46.mlp.experts.75.down_proj.weight', 'model.layers.46.mlp.experts.75.gate_proj.weight', 'model.layers.46.mlp.experts.75.up_proj.weight', 'model.layers.46.mlp.experts.76.down_proj.weight', 'model.layers.46.mlp.experts.76.gate_proj.weight', 'model.layers.46.mlp.experts.76.up_proj.weight', 'model.layers.46.mlp.experts.77.down_proj.weight', 'model.layers.46.mlp.experts.77.gate_proj.weight', 'model.layers.46.mlp.experts.77.up_proj.weight', 'model.layers.46.mlp.experts.78.down_proj.weight', 'model.layers.46.mlp.experts.78.gate_proj.weight', 'model.layers.46.mlp.experts.78.up_proj.weight', 'model.layers.46.mlp.experts.79.down_proj.weight', 'model.layers.46.mlp.experts.79.gate_proj.weight', 'model.layers.46.mlp.experts.79.up_proj.weight', 'model.layers.46.mlp.experts.8.down_proj.weight', 'model.layers.46.mlp.experts.8.gate_proj.weight', 'model.layers.46.mlp.experts.8.up_proj.weight', 'model.layers.46.mlp.experts.80.down_proj.weight', 'model.layers.46.mlp.experts.80.gate_proj.weight', 'model.layers.46.mlp.experts.80.up_proj.weight', 'model.layers.46.mlp.experts.81.down_proj.weight', 'model.layers.46.mlp.experts.81.gate_proj.weight', 'model.layers.46.mlp.experts.81.up_proj.weight', 'model.layers.46.mlp.experts.82.down_proj.weight', 'model.layers.46.mlp.experts.82.gate_proj.weight', 'model.layers.46.mlp.experts.82.up_proj.weight', 'model.layers.46.mlp.experts.83.down_proj.weight', 'model.layers.46.mlp.experts.83.gate_proj.weight', 'model.layers.46.mlp.experts.83.up_proj.weight', 'model.layers.46.mlp.experts.84.down_proj.weight', 'model.layers.46.mlp.experts.84.gate_proj.weight', 'model.layers.46.mlp.experts.84.up_proj.weight', 'model.layers.46.mlp.experts.85.down_proj.weight', 'model.layers.46.mlp.experts.85.gate_proj.weight', 'model.layers.46.mlp.experts.85.up_proj.weight', 'model.layers.46.mlp.experts.86.down_proj.weight', 'model.layers.46.mlp.experts.86.gate_proj.weight', 'model.layers.46.mlp.experts.86.up_proj.weight', 'model.layers.46.mlp.experts.87.down_proj.weight', 'model.layers.46.mlp.experts.87.gate_proj.weight', 'model.layers.46.mlp.experts.87.up_proj.weight', 'model.layers.46.mlp.experts.88.down_proj.weight', 'model.layers.46.mlp.experts.88.gate_proj.weight', 'model.layers.46.mlp.experts.88.up_proj.weight', 'model.layers.46.mlp.experts.89.down_proj.weight', 'model.layers.46.mlp.experts.89.gate_proj.weight', 'model.layers.46.mlp.experts.89.up_proj.weight', 'model.layers.46.mlp.experts.9.down_proj.weight', 'model.layers.46.mlp.experts.9.gate_proj.weight', 'model.layers.46.mlp.experts.9.up_proj.weight', 'model.layers.46.mlp.experts.90.down_proj.weight', 'model.layers.46.mlp.experts.90.gate_proj.weight', 'model.layers.46.mlp.experts.90.up_proj.weight', 'model.layers.46.mlp.experts.91.down_proj.weight', 'model.layers.46.mlp.experts.91.gate_proj.weight', 'model.layers.46.mlp.experts.91.up_proj.weight', 'model.layers.46.mlp.experts.92.down_proj.weight', 'model.layers.46.mlp.experts.92.gate_proj.weight', 'model.layers.46.mlp.experts.92.up_proj.weight', 'model.layers.46.mlp.experts.93.down_proj.weight', 'model.layers.46.mlp.experts.93.gate_proj.weight', 'model.layers.46.mlp.experts.93.up_proj.weight', 'model.layers.46.mlp.experts.94.down_proj.weight', 'model.layers.46.mlp.experts.94.gate_proj.weight', 'model.layers.46.mlp.experts.94.up_proj.weight', 'model.layers.46.mlp.experts.95.down_proj.weight', 'model.layers.46.mlp.experts.95.gate_proj.weight', 'model.layers.46.mlp.experts.95.up_proj.weight', 'model.layers.46.mlp.experts.96.down_proj.weight', 'model.layers.46.mlp.experts.96.gate_proj.weight', 'model.layers.46.mlp.experts.96.up_proj.weight', 'model.layers.46.mlp.experts.97.down_proj.weight', 'model.layers.46.mlp.experts.97.gate_proj.weight', 'model.layers.46.mlp.experts.97.up_proj.weight', 'model.layers.46.mlp.experts.98.down_proj.weight', 'model.layers.46.mlp.experts.98.gate_proj.weight', 'model.layers.46.mlp.experts.98.up_proj.weight', 'model.layers.46.mlp.experts.99.down_proj.weight', 'model.layers.46.mlp.experts.99.gate_proj.weight', 'model.layers.46.mlp.experts.99.up_proj.weight', 'model.layers.46.mlp.gate.e_score_correction_bias', 'model.layers.46.mlp.gate.weight', 'model.layers.46.mlp.shared_experts.down_proj.weight', 'model.layers.46.mlp.shared_experts.gate_proj.weight', 'model.layers.46.mlp.shared_experts.up_proj.weight', 'model.layers.46.post_attention_layernorm.weight', 'model.layers.46.self_attn.k_proj.bias', 'model.layers.46.self_attn.k_proj.weight', 'model.layers.46.self_attn.o_proj.weight', 'model.layers.46.self_attn.q_proj.bias', 'model.layers.46.self_attn.q_proj.weight', 'model.layers.46.self_attn.v_proj.bias', 'model.layers.46.self_attn.v_proj.weight', 'model.layers.46.shared_head.head.weight', 'model.layers.46.shared_head.norm.weight']\n",
      "- This IS expected if you are initializing Glm4MoeForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Glm4MoeForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import Glm4MoeForCausalLM\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "model = Glm4MoeForCausalLM.from_pretrained(\n",
    "    'ramdisk/GLM-4.5-Air', \n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "712d696a-035c-48ba-a5f8-7f2b042d1312",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = torch.load('nfs/nfs/GLM-4.5-Air-bf16/model_state_dict.pt', map_location='cpu')\n",
    "keys = mapping.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7001f4d7-cc18-4be1-a86b-98ed0eb9eeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72356849-e201-49c2-8f8b-1d051c460760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 46/46 [00:02<00:00, 19.05it/s]\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(model.config.num_hidden_layers)):\n",
    "    A = f'_orig_mod.model.layers.{i}.mlp.gate_lora.A'\n",
    "    if A in mapping:\n",
    "        B = f'_orig_mod.model.layers.{i}.mlp.gate_lora.B'\n",
    "        a = mapping[A]\n",
    "        for k in range(a.shape[0]):\n",
    "            W = f'model.layers.{i}.mlp.experts.{k}.gate_proj.weight'\n",
    "            W = state_dict[W]\n",
    "            A_ = mapping[A][k].to(W.device)\n",
    "            B_ = mapping[B][k].to(W.device)\n",
    "            m = torch.matmul(A_, B_) * 2.0\n",
    "            W += m.T.to(W.dtype)\n",
    "            \n",
    "    A = f'_orig_mod.model.layers.{i}.mlp.up_lora.A'\n",
    "    if A in mapping:\n",
    "        B = f'_orig_mod.model.layers.{i}.mlp.up_lora.B'\n",
    "        a = mapping[A]\n",
    "        for k in range(a.shape[0]):\n",
    "            W = f'model.layers.{i}.mlp.experts.{k}.up_proj.weight'\n",
    "            W = state_dict[W]\n",
    "            A_ = mapping[A][k].to(W.device)\n",
    "            B_ = mapping[B][k].to(W.device)\n",
    "            m = torch.matmul(A_, B_) * 2.0\n",
    "            W += m.T.to(W.dtype)\n",
    "\n",
    "    A = f'_orig_mod.model.layers.{i}.mlp.down_lora.A'\n",
    "    if A in mapping:\n",
    "        B = f'_orig_mod.model.layers.{i}.mlp.down_lora.B'\n",
    "        a = mapping[A]\n",
    "        for k in range(a.shape[0]):\n",
    "            W = f'model.layers.{i}.mlp.experts.{k}.down_proj.weight'\n",
    "            W = state_dict[W]\n",
    "            A_ = mapping[A][k].to(W.device)\n",
    "            B_ = mapping[B][k].to(W.device)\n",
    "            m = torch.matmul(A_, B_) * 2.0\n",
    "            W += m.T.to(W.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "051a3bae-328f-49f7-86bc-e343e5b2ab06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 322/322 [00:00<00:00, 1341.64it/s]\n"
     ]
    }
   ],
   "source": [
    "keys_lora = [k.split('.lora')[0] for k in keys if '.lora' in k]\n",
    "keys_lora = sorted(list(set(keys_lora)))\n",
    "for k in tqdm(keys_lora):\n",
    "    k_ori = k.replace('_orig_mod.', '') + '.weight'\n",
    "    post_A = '.lora_A'\n",
    "    post_B = '.lora_B'\n",
    "    A = k + post_A\n",
    "    B = k + post_B\n",
    "    W = state_dict[k_ori]\n",
    "    A = mapping[A].to(W.device)\n",
    "    B = mapping[B].to(W.device)\n",
    "    m = torch.matmul(A.t(), B.t()) * 2.0\n",
    "    W += m.T.to(W.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dba3627f-8d10-4cb9-aa71-7a60f168d076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[151331, 151333, 151335,    198,   5338,     11,    498,   1430,    311,\n",
       "           1744,   3019,  14309,  29101,    304,   8640,    352,     11,   1283,\n",
       "            429,     11,   2182,    697,   1590,   4226,   2878,  57564,  78439,\n",
       "           6257,  12940, 151336,    271,     33,    661,    585,  35513,  69939,\n",
       "          40659,    278,     11,  25201,    524,  49289,    512,   4554,  10918,\n",
       "          59982,     11,    294,   3083,   6568,   7978,   8309,   1853,    440,\n",
       "          17771,  22830,    382,    465,  62462,   1466,   1962,  78407,   1466,\n",
       "            198, 151337]], device='cuda:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('ramdisk/GLM-4.5-Air')\n",
    "\n",
    "q = \"\"\"\n",
    "Budak itu sangat nakal, pantang orang leka sedikit, duit syiling pun dikebasnya.\n",
    "\n",
    "terjemah ke kedah\n",
    "\"\"\"\n",
    "\n",
    "system = 'First, you try to think step-by-step in {{lang}}, after that, put your final answer within $\\\\boxed{}$.'\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system.replace('{{lang}}', 'malay')},\n",
    "    {\"role\": \"user\", \"content\": q},\n",
    "]\n",
    "\n",
    "row = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt=True,\n",
    "    tokenize=False\n",
    ")\n",
    "input_ids = tokenizer(row, add_special_tokens = False, return_tensors = 'pt').to(model.device)['input_ids']\n",
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92a333b6-8574-48cc-b9fb-51738eb43037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[gMASK]<sop><|system|>\\nFirst, you try to think step-by-step in malay, after that, put your final answer within $\\\\boxed{}$.<|user|>\\n\\nBudak itu sangat nakal, pantang orang leka sedikit, duit syiling pun dikebasnya.\\n\\nterjemah ke kedah\\n<|assistant|>\\n<think>Baik, saya akan jelaskan dengan sangat terperinci dan langkah demi langkah bagaimana ayat Bahasa Melayu standard di atas ditukar kepada dialek Kedah. Saya akan membahagikan ayat kepada beberapa bahagian dan menerangkan setiap perubahan dari segi perkataan, struktur, bunyi, dan konteks budaya.\\n\\n## **Analisis Ayat Standard:**\\n\\n**Ayat Asal (Bahasa Melayu Standard):**\\n\\n> *Budak itu sangat nakal, pantang orang leka sedikit, duit syiling'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_kwargs = {\"max_new_tokens\": 128, \"do_sample\": True, \"temperature\": 0.6, \"top_p\": None, \"top_k\": None}\n",
    "\n",
    "output_ids = model.generate(input_ids, **gen_kwargs)\n",
    "response = tokenizer.batch_decode(output_ids)[0]\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecbef4a-d69f-4998-850d-62f7ca493ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "malaysian-reasoning",
   "language": "python",
   "name": "malaysian-reasoning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
